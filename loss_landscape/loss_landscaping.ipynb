{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f7c0618-3199-4ad5-9922-3074c9a51a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = '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' #'your_hf_access_token'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a2525f-dbcc-4706-baa5-951b58afd6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model_id = \"meta-llama/Llama-2-7b-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7adf727-4984-4b97-adfc-592b12e82c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load model and tokenizer\n",
    "# model_id = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
    "model = LlamaForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, token=token)#, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656c50c-dfcf-4c89-ab54-02dfb8d1c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_device = torch.device(\"cuda:0\")\n",
    "model.to(updated_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bfd674-f11b-412b-a5ec-a2206ed1b3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random orthogonal directions\n",
    "def generate_random_directions(param_size, device):\n",
    "    vec1 = torch.randn(param_size, device=device)\n",
    "    vec2 = torch.randn(param_size, device=device)\n",
    "    vec2 = vec2 - (torch.sum(vec1 * vec2) / torch.sum(vec1 * vec1)) * vec1  # Orthogonalize vec2\n",
    "    vec1 = vec1 / torch.norm(vec1)\n",
    "    vec2 = vec2 / torch.norm(vec2)\n",
    "    return vec1, vec2\n",
    "\n",
    "# Compute loss on a given dataset\n",
    "def compute_loss(inputs, labels):\n",
    "    inputs = {key: value.to(updated_device) for key, value in inputs.items()}\n",
    "    labels = labels.to(updated_device)\n",
    "    outputs = model(**inputs)\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(outputs.logits.view(-1, outputs.logits.size(-1)), labels.view(-1))\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90937a77-6e49-47b2-bf5c-877122ce99a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss landscape\n",
    "primary_device = torch.device(\"cpu\")\n",
    "param_vector = torch.cat([p.flatten() for p in model.parameters()]).to(primary_device)\n",
    "param_size = param_vector.size(0)\n",
    "vec1, vec2 = generate_random_directions(param_size, primary_device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0035d1-97b7-4e40-9559-9b8db87e24f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev=torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617d89a-16a6-4761-8241-0aafcdbe56c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg = \"At what seemed like the absolute nadir of my creative block I\\u2019d had a vivid dream in which I was crossing the San Francisco Bay Bridge. In that dream I looked out to see a huge oil tanker sitting in the water. As I watched, it slowly rose up like a Saturn rocket and blasted out of the bay and into the sky. I could see the rust-colored metal oxide of its hull as it took off. Shortly after, possibly the very next day, I sat down in my studio to find, almost as if they were waiting for me, the powerful pounding E-minor chords that launch the piece. From there it proceeded to take shape with great speed, almost as if the floodgates had been opened and nearly two years of pent-up energy and ideas came rushing forth.\\nLike a brooding, egocentric father, impossible to please, he loomed in my consciousness, sometimes as the embodiment of a mercurial creative force and other times as a Lethal defoliant, ready to kill off any and all sprouts of life that might appear in its immediate range.\\nHarmonielehre is parody of a different sort in that it bears a \\u201csubsidiary relation\\u201d to a model (in this case a number of signal works from the turn of the century like [Schoenberg\\u2019s] Gurrelieder and the Sibelius Fourth Symphony), but it does so without the intent to ridicule. It is a large, three-movement work for orchestra that marries the developmental techniques of Minimalism with the harmonic and expressive world of fin de si\\u00e8cle late Romanticism. It was a conceit that could only be attempted once. The shades of Mahler, Sibelius, Debussy, and the young Schoenberg are everywhere in this strange piece. This is a work that looks at the past in what I suspect is \\u201cpostmodernist\\u201d spirit, but, unlike Grand Pianola Music or Nixon in China, it does so entirely without irony.\\nIn the first movement, listen to the way the voices of the orchestra come alive, creating a vibrant, shimmering tapestry of color. Gradually, the exhilarating sense of pulse dissolves into a more serene soundscape, opening the door to a soaringly expansive, yet endlessly searching, melody. Around the 10:40 mark, there are strands of late Mahler. A few moments later, we find ourselves floating through a majestic sea of Wagnerian chromaticism. There are striking similarities to this equally Wagnerian passage from the beginning of Schoenberg\\u2019s Gurrelieder.\\nThe second movement, The Anfortas Wound, enters the gloomy darkness of Sibelius\\u2019 Fourth Symphony. At the movement\\u2019s climax, there is an allusion to the shrieking, virtual tone cluster (akin to placing both fists on the piano keyboard) of Mahler\\u2019s unfinished Tenth Symphony.\\nAt the time (1984\\u201485) I was still deeply involved in the study of C. G. Jung\\u2019s writings, particularly his examination of Medieval mythology. I was deeply affected by Jung\\u2019s discussion of the character of Anfortas, the king whose wounds could never be healed. As a critical archetype, Anfortas symbolized a condition of sickness of the soul that curses it with a feeling of impotence and depression. In this slow, moody movement entitled \\u201cThe Anfortas Wound\\u201d a long, elegiac trumpet solo floats over a delicately shifting screen of minor triads that pass like spectral shapes from one family of instruments to the other. Two enormous climaxes rise up out of the otherwise melancholy landscape, the second one being an obvious homage to Mahler\\u2019s last, unfinished symphony.\\nThe Zappaesque title refers to a dream I\\u2019d had shortly after the birth of our daughter, Emily, who was briefly dubbed \\u201cQuackie\\u201d during her infancy. In the dream, she rides perched on the shoulder of the Medieval mystic, Meister Eckhardt, as they hover among the heavenly bodies like figures painted on the high ceilings of old cathedrals.\\nThe serene, childlike innocence of the opening bars captures this dream image- perhaps a distant allusion to ultimate peace of the final movement of Mahler\\u2019s Fourth Symphony. The music moves beyond this initial \\u201ccradle song,\\u201d concluding with \\u201ca vast harmonic struggle\\u201d between the keys of E and E-flat major. Adams has called the euphoric ultimate resolution \\u201ca buffalo herd in E-flat major.\\u201d This harmonic \\u201cduel\\u201d is foreshadowed in the final movement of Adams\\u2019 1983 electronic work, Light Over Water.\\nSan Francisco Symphony, Michael Tilson Thomas iTunes (This 2012 live concert recording is featured, above).\\nSan Francisco Symphony, Edo de Waart Amazon -This was the first recording, made days after the premiere. The parts contained proofreading errors and Adams later revised the final movement\\u2019s ending. But it\\u2019s still an excellent recording which captures the spirit of the music.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4fb34-7b18-4da7-bdf3-b5b1e52ae599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grid for perturbations\n",
    "steps = 20\n",
    "delta = 1\n",
    "x_range = torch.linspace(-steps * delta, steps * delta, steps, device=dev)\n",
    "y_range = torch.linspace(-steps * delta, steps * delta, steps, device=dev)\n",
    "loss_grid = torch.zeros((steps, steps), device=dev)\n",
    "\n",
    "# # Store original parameters\n",
    "# original_params = {name: p.clone() for name, p in model.named_parameters()}\n",
    "\n",
    "# Calculate loss landscape\n",
    "# Calculate loss landscape\n",
    "ck = 0\n",
    "for i, x in enumerate(x_range):\n",
    "    for j, y in enumerate(y_range):\n",
    "        # print(\n",
    "        ck+=1\n",
    "        print(ck)\n",
    "        param_vector = param_vector.to(device=dev)\n",
    "        vec1 = vec1.to(device=dev)\n",
    "        vec2 = vec2.to(device=dev)\n",
    "        # x = x_range[0]\n",
    "        # y = y_range[0]\n",
    "        x = x.to(device=dev)\n",
    "        y = y.to(device=dev)\n",
    "        perturbed_vector = param_vector + x * vec1 + y * vec2\n",
    "        vec1 = vec1.to(device='cpu')\n",
    "        vec2 = vec2.to(device='cpu')\n",
    "        torch.cuda.empty_cache()\n",
    "        start = 0\n",
    "        for name, p in model.named_parameters():\n",
    "            end = start + p.numel()\n",
    "            p.data = perturbed_vector[start:end].view(p.size()).to(updated_device)\n",
    "            start = end\n",
    "\n",
    "        # Prepare dummy input and labels\n",
    "        inputs = tokenizer(msg, return_tensors=\"pt\")\n",
    "        labels = inputs[\"input_ids\"]\n",
    "\n",
    "        # Compute loss\n",
    "        loss_grid[i, j] = compute_loss(inputs, labels)\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6aa847b-9ffb-4f73-a2a4-a682b4189263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the loss landscape\n",
    "loss_grid = loss_grid.cpu().numpy()\n",
    "X, Y = np.meshgrid(x_range.cpu().numpy(), y_range.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ce0f3-802f-453b-80b6-dd295d5a1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.contourf(X, Y, loss_grid, levels=5, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Loss\")\n",
    "plt.xlabel(\"Direction 1\")\n",
    "plt.ylabel(\"Direction 2\")\n",
    "plt.title(\"Loss Landscape Visualization\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
