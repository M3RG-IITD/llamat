{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "374c2279-92ee-4854-9c5b-c87345b9e8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_atom_cnt(task, pred):\n",
    "    # task = atom count\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_dimensions(task, pred):\n",
    "    # task = dimensions, pred is a list\n",
    "    if \"lengths of the lattice vectors\" in task['input']:\n",
    "        lengths = [float(x) for x in task['output'].split(',')]\n",
    "        mse = np.mean((lengths - pred) ** 2)\n",
    "        return mses\n",
    "    else:\n",
    "        angles = [float(x) for x in task['output'].split(',')]\n",
    "        mae = np.mean(abs(angles - pred))\n",
    "        return mae\n",
    "\n",
    "def eval_atom_name(task, pred):\n",
    "    # task = atom name\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_spacegroup(task, pred):\n",
    "    # task = space group\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_cell_volume(task, pred):\n",
    "    # task = cell_volume\n",
    "    return abs(task['output']-pred)\n",
    "\n",
    "def eval_formula(task, pred):\n",
    "    # task = formula\n",
    "    return task['output']==pred\n",
    "\n",
    "def eval_replace(task, pred):\n",
    "    # task = replace\n",
    "    return task['output']==pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20ae8f75-bfbe-4135-ab04-4e54eef9e629",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (389705309.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def verify_gen_format(output):\n",
    "    lines = output.split('\\n')\n",
    "    if len(lines)%2:\n",
    "        return 0\n",
    "    \n",
    "    lengths = lines[0]\n",
    "    angles = lines[1]\n",
    "    for i in range(2, len(lines), 2):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f6c3b-a284-47d3-aea3-8b29936c06ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_infill():\n",
    "\n",
    "def eval_dimensions_gen():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1b0d1b-1e0c-486d-92f9-5c9bf1d38c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structure(cif_str):\n",
    "    structure = Structure.from_str(cif_str, fmt=\"cif\")\n",
    "\n",
    "#     structure.translate_sites(\n",
    "#         indices=range(len(structure.sites)), vector=np.random.uniform(size=(3,))\n",
    "#     )\n",
    "    return structure\n",
    "\n",
    "def get_crystal_string_nate(structure):\n",
    "    lengths = structure.lattice.parameters[:3]\n",
    "    angles = structure.lattice.parameters[3:]\n",
    "    atom_ids = structure.species\n",
    "    frac_coords = structure.frac_coords\n",
    "\n",
    "    crystal_str = \\\n",
    "        \" \".join([\"{0:.1f}\".format(x) for x in lengths]) + \"\\n\" + \\\n",
    "        \" \".join([str(int(x)) for x in angles]) + \"\\n\" + \\\n",
    "        \"\\n\".join([\n",
    "            str(t) + \"\\n\" + \" \".join([\n",
    "                \"{0:.2f}\".format(x) for x in c\n",
    "            ]) for t,c in zip(atom_ids, frac_coords)\n",
    "        ])\n",
    "\n",
    "    return crystal_str\n",
    "\n",
    "def get_crystal_string(structure):\n",
    "    lengths = structure.lattice.parameters[:3]\n",
    "    angles = structure.lattice.parameters[3:]\n",
    "    atom_ids = structure.species\n",
    "    frac_coords = structure.frac_coords\n",
    "\n",
    "    lens = [float(\"{0:.1f}\".format(x)) for x in lengths]\n",
    "    angs = [int(x) for x in angles]\n",
    "    coords = \"\\n\".join([\n",
    "            str(t) + \"\\n\" + \" \".join([\n",
    "                \"{0:.2f}\".format(x) for x in c\n",
    "            ]) for t,c in zip(atom_ids, frac_coords)\n",
    "    ])\n",
    "\n",
    "    crystal = {\n",
    "        \"lengths\": lens,\n",
    "        \"angles\": angs,\n",
    "        \"coordinates\": coords\n",
    "    }\n",
    "\n",
    "    return json.dumps(crystal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefdd64a-c307-4d84-9000-cbaeb4762574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import vllm\n",
    "import torch\n",
    "import string\n",
    "import re\n",
    "import collections\n",
    "from sklearn.metrics import f1_score\n",
    "import Levenshtein\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, LlamaTokenizer\n",
    "import datetime\n",
    "from functools import reduce\n",
    "from huggingface_hub import login\n",
    "\n",
    "# daddy_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f5331dc-e2f6-49ac-ad96-33ea28e3a590",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "/scratch/cse/btech/cs1200448/MatLlama/ft-checkpoints/ift_cif5/1650/iter_0004000 does not appear to have a file named config.json. Checkout 'https://huggingface.co//scratch/cse/btech/cs1200448/MatLlama/ft-checkpoints/ift_cif5/1650/iter_0004000/tree/None' for available files.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m      9\u001b[0m num_seeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     11\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/cse/btech/cs1200448/MatLlama/ft-checkpoints/ift_cif5/1650/iter_0004000\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/cse/btech/cs1200448/llama-weights/7b/tokenizer.model\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# \"gpu_memory_utilization\":args.mem_util,\u001b[39;00m\n\u001b[1;32m     18\u001b[0m }\n\u001b[0;32m---> 20\u001b[0m client \u001b[38;5;241m=\u001b[39m \u001b[43mvllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/vllm/entrypoints/llm.py:109\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, enforce_eager, max_context_len_to_capture, disable_custom_all_reduce, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     91\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m     92\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     93\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    108\u001b[0m )\n\u001b[0;32m--> 109\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/vllm/engine/llm_engine.py:386\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates an LLM engine from the engine arguments.\"\"\"\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;66;03m# Create the engine configs.\u001b[39;00m\n\u001b[0;32m--> 386\u001b[0m engine_configs \u001b[38;5;241m=\u001b[39m \u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_engine_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m parallel_config \u001b[38;5;241m=\u001b[39m engine_configs[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# Initialize the cluster.\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/vllm/engine/arg_utils.py:287\u001b[0m, in \u001b[0;36mEngineArgs.create_engine_configs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_engine_configs\u001b[39m(\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    284\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[ModelConfig, CacheConfig, ParallelConfig, SchedulerConfig,\n\u001b[1;32m    285\u001b[0m            DeviceConfig, Optional[LoRAConfig]]:\n\u001b[1;32m    286\u001b[0m     device_config \u001b[38;5;241m=\u001b[39m DeviceConfig(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 287\u001b[0m     model_config \u001b[38;5;241m=\u001b[39m \u001b[43mModelConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer_revision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_model_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantization\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menforce_eager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_context_len_to_capture\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     cache_config \u001b[38;5;241m=\u001b[39m CacheConfig(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblock_size,\n\u001b[1;32m    294\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpu_memory_utilization,\n\u001b[1;32m    295\u001b[0m                                \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mswap_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkv_cache_dtype,\n\u001b[1;32m    296\u001b[0m                                model_config\u001b[38;5;241m.\u001b[39mget_sliding_window())\n\u001b[1;32m    297\u001b[0m     parallel_config \u001b[38;5;241m=\u001b[39m ParallelConfig(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipeline_parallel_size,\n\u001b[1;32m    298\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_parallel_size,\n\u001b[1;32m    299\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworker_use_ray,\n\u001b[1;32m    300\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_parallel_loading_workers,\n\u001b[1;32m    301\u001b[0m                                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_custom_all_reduce)\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/vllm/config.py:111\u001b[0m, in \u001b[0;36mModelConfig.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, trust_remote_code, download_dir, load_format, dtype, seed, revision, code_revision, tokenizer_revision, max_model_len, quantization, enforce_eager, max_context_len_to_capture)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload_dir \u001b[38;5;241m=\u001b[39m model_path\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer \u001b[38;5;241m=\u001b[39m model_path\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_config \u001b[38;5;241m=\u001b[39m \u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m _get_and_verify_dtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_config, dtype)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_model_len \u001b[38;5;241m=\u001b[39m _get_and_verify_max_len(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhf_config,\n\u001b[1;32m    115\u001b[0m                                              max_model_len)\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/vllm/transformers_utils/config.py:30\u001b[0m, in \u001b[0;36mget_config\u001b[0;34m(model, trust_remote_code, revision, code_revision)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m config\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 30\u001b[0m     config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcode_revision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcode_revision\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m trust_remote_code \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m     37\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires you to execute the configuration file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e)):\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/transformers/models/auto/configuration_auto.py:928\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    925\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    926\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 928\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    930\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/transformers/configuration_utils.py:631\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    633\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/transformers/configuration_utils.py:686\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    682\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 686\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    700\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    701\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama-inference/lib/python3.9/site-packages/transformers/utils/hub.py:369\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misfile(resolved_file):\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _raise_exceptions_for_missing_entries:\n\u001b[0;32m--> 369\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not appear to have a file named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Checkout \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/tree/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available files.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: /scratch/cse/btech/cs1200448/MatLlama/ft-checkpoints/ift_cif5/1650/iter_0004000 does not appear to have a file named config.json. Checkout 'https://huggingface.co//scratch/cse/btech/cs1200448/MatLlama/ft-checkpoints/ift_cif5/1650/iter_0004000/tree/None' for available files."
     ]
    }
   ],
   "source": [
    "valfile = []\n",
    "with open(\"/scratch/cse/btech/cs1200448/MatLlama/ift_cif/val.jsonl\", 'r') as f:\n",
    "    valfile = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "valinputs = [f\"<|im_start|>system\\n{i['system']}<|im_end|>\\n\"+f\"<|im_start|>question\\n{i['input']}<|im_end|>\\n\"+\"<|im_start|>answer\\n\" for i in valfile]\n",
    "\n",
    "init_seed = 2\n",
    "seed = 1\n",
    "num_seeds = 3\n",
    "\n",
    "kwargs = {\n",
    "    \"model\": \"/scratch/cse/btech/cs1200448/MatLlama/ft-checkpoints/ift_cif_hf\",\n",
    "    \"tokenizer\": \"/scratch/cse/btech/cs1200448/llama-weights/7b/tokenizer.model\",\n",
    "    \"trust_remote_code\": True,\n",
    "    \"tensor_parallel_size\": 1,\n",
    "    \"seed\":seed,\n",
    "    # \"gpu_memory_utilization\":args.mem_util,\n",
    "}\n",
    "\n",
    "client = vllm.LLM(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3129ef-9854-4097-b0cb-4ae48b3b450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for _ in range(1, num_seeds+1):\n",
    "seed = seed * init_seed\n",
    "\n",
    "response = client.generate(valinputs, sampling_params=vllm.SamplingParams(\n",
    "        skip_special_tokens=True,\n",
    "        best_of=1,\n",
    "        presence_penalty=0.0,\n",
    "        frequency_penalty=1.0,\n",
    "        top_k=50,\n",
    "        top_p=1.0,\n",
    "        temperature=0.75,\n",
    "        stop=[\"<|im_start|>\", \"<|im_end|>\"],\n",
    "        use_beam_search=False,\n",
    "        max_tokens=300,\n",
    "        logprobs=2\n",
    "    ))\n",
    "predictions = [i.outputs[0].text for i in response]\n",
    "\n",
    "def most_similar_answer(a,answer_set):\n",
    "    a = a.strip().replace(' ', '')\n",
    "    if(a in answer_set):\n",
    "        return a\n",
    "    dis = [Levenshtein.distance(a,x) for x in answer_set]\n",
    "    idx = np.argmin(dis)\n",
    "    return answer_set[idx]\n",
    "\n",
    "for _, sample in enumerate(valfile):\n",
    "    task = sample['task']\n",
    "    system = sample['system']\n",
    "    output = predictions[_]\n",
    "    print(sample['input'])\n",
    "    print(sample['output'])\n",
    "    print(\"--------\")\n",
    "    print(output)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f214d9-c7fc-41a2-8f42-0e09e84584eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "   # if len(output) == 0: # cases with prompt length > ctxlen\n",
    "        #     continue\n",
    "        # if 'SOFC' in system:\n",
    "        #     task = 'sc'\n",
    "        #     dataset = 'sofc_sent'\n",
    "        # elif 'named entity' in system:\n",
    "        #     task = 'ner'\n",
    "        #     if 'b-dsc' in system:\n",
    "        #         dataset = 'matscholar'\n",
    "        #     elif 'b-device' in system:\n",
    "        #         dataset = 'sofc_token'\n",
    "        #     elif 'doping' in system:\n",
    "        #         dataset = 'sc_comics'\n",
    "        # elif 'synthesis action' in system:\n",
    "        #     task = 'sar'\n",
    "        #     dataset = 'synthesis_actions'\n",
    "        # elif 'slots' in system:\n",
    "        #     task = 'sf'\n",
    "        #     dataset = 'sofc_token'\n",
    "        # elif 'event, identify the roles of the arguments' in system:\n",
    "        #     task = 'ee'\n",
    "        #     dataset = 'sc_comics'\n",
    "        # elif 'extract relation' in system:\n",
    "        #     task = 're'\n",
    "        #     for ds in kw[task]:\n",
    "        #         if kw[task][ds][0] in system:\n",
    "        #             dataset = ds\n",
    "        #             break   \n",
    "        # elif 'inorganic glass' in system:\n",
    "        #     task = 'pc'\n",
    "        #     dataset = 'glass_non_glass'\n",
    "        # else:\n",
    "        #     task = 'qna'\n",
    "        #     dataset = 'squad'\n",
    "        \n",
    "        # assert task != None\n",
    "        # assert dataset != None\n",
    "        \n",
    "        # if task in [\"ner\", \"sf\", \"ee\", \"sar\"]:\n",
    "        #     answer = [i.split(\" : \") for i in answer.lower().split('\\n')]\n",
    "        #     try:\n",
    "        #         temp = [[j.strip().lower() for j in i.split(\":\")] for i in output.split('\\n')]\n",
    "        #         temp = [i for i in temp if len(i) == 2]\n",
    "        #         output = temp\n",
    "        #     except:\n",
    "        #         print(f\"for tc {_}, output pattern mismatched. {output}\")\n",
    "        # else:\n",
    "        #     answer = answer.strip().lower()\n",
    "        #     output = output.strip().lower()\n",
    "    \n",
    "        # out_dict[task][dataset].append((answer, output))\n",
    "\n",
    "    # scores = {i : [] for i in tasks}\n",
    "    # scores[\"ner\"] = {i : (0,0) for i in [\"matscholar\", \"sofc_token\", \"sc_comics\"]}\n",
    "    # scores[\"pc\"] = {i : (0,0) for i in [\"glass_non_glass\"]}\n",
    "    # scores[\"sf\"] = {i : (0,0) for i in [\"sofc_token\"]}\n",
    "    # scores[\"ee\"] = {i : (0,0) for i in [\"sc_comics\"]}\n",
    "    # scores[\"re\"] = {i : (0,0) for i in [\"structured_re\", \"sc_comics\"]}\n",
    "    # scores[\"sar\"] = {i : (0,0) for i in [\"synthesis_actions\"]}\n",
    "    # scores[\"sc\"] = {i : (0,0) for i in [\"sofc_sent\"]}\n",
    "    # scores[\"qna\"] = {i : (0,0) for i in [\"squad\"]}\n",
    "\n",
    "    # def evaluate(task, dataset):\n",
    "    #     all_gt = []\n",
    "    #     all_pred = []\n",
    "    #     for gt, pred in out_dict[task][dataset]:\n",
    "    #         dict = {}\n",
    "    #         for word, entity in gt:\n",
    "    #             dict[word] = [entity, 'O']\n",
    "                    \n",
    "    #         for word, entity in pred:\n",
    "    #             to_put = most_similar_answer(entity, kw[task][dataset])\n",
    "    #             if word in dict:\n",
    "    #                 dict[word][1] = to_put\n",
    "    #             else:\n",
    "    #                 dict[word] = ['O', to_put]\n",
    "                    \n",
    "    #         for i in dict.values():\n",
    "    #             all_gt.append(i[0])\n",
    "    #             all_pred.append(i[1])\n",
    "    \n",
    "    #     micro_f1 = f1_score(all_gt, all_pred, average='micro', labels = list(kw[task][dataset]))\n",
    "    #     macro_f1 = f1_score(all_gt, all_pred, average='macro', labels = list(kw[task][dataset]))\n",
    "    #     scores[task][dataset] = micro_f1, macro_f1\n",
    "    #     return micro_f1, macro_f1\n",
    "\n",
    "    # def evaluate_pc(dataset):\n",
    "    #     out_dict['pc'][dataset] = [(most_similar_answer(i[0], kw['pc'][dataset]), most_similar_answer(i[1], kw['pc'][dataset])) for i in out_dict['pc'][dataset]]\n",
    "    \n",
    "    #     micro_f1 = f1_score(*list(zip(*out_dict['pc'][dataset])), average='micro', labels = list(kw['pc'][dataset]))\n",
    "    #     macro_f1 = f1_score(*list(zip(*out_dict['pc'][dataset])), average='macro', labels = list(kw['pc'][dataset]))\n",
    "    #     scores['pc'][dataset] = micro_f1, macro_f1\n",
    "    #     return micro_f1, macro_f1\n",
    "    \n",
    "    # def evaluate_sc(dataset):\n",
    "    #     out_dict['sc'][dataset] = [(most_similar_answer(i[0], kw['sc'][dataset]), most_similar_answer(i[1], kw['sc'][dataset])) for i in out_dict['sc'][dataset]]\n",
    "        \n",
    "    #     micro_f1 = f1_score(*list(zip(*out_dict['sc'][dataset])), average='micro', labels = list(kw['sc'][dataset]))\n",
    "    #     macro_f1 = f1_score(*list(zip(*out_dict['sc'][dataset])), average='macro', labels = list(kw['sc'][dataset]))\n",
    "    #     scores['sc'][dataset] = micro_f1, macro_f1\n",
    "    #     return micro_f1, macro_f1\n",
    "    \n",
    "    # def evaluate_re(dataset):\n",
    "    #     out_dict['re'][dataset] = [(most_similar_answer(i[0], kw['re'][dataset]), most_similar_answer(i[1], kw['re'][dataset])) for i in out_dict['re'][dataset]]\n",
    "        \n",
    "    #     micro_f1 = f1_score(*list(zip(*out_dict['re'][dataset])), average='micro', labels = list(kw['re'][dataset]))\n",
    "    #     macro_f1 = f1_score(*list(zip(*out_dict['re'][dataset])), average='macro', labels = list(kw['re'][dataset]))\n",
    "    #     scores['re'][dataset] = micro_f1, macro_f1\n",
    "    #     return micro_f1, macro_f1\n",
    "\n",
    "    # def normalize_answer(s):\n",
    "    #     \"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"\n",
    "    #     def remove_articles(text):\n",
    "    #         regex = re.compile(r'\\b(a|an|the)\\b', re.UNICODE)\n",
    "    #         return re.sub(regex, ' ', text)\n",
    "    #     def white_space_fix(text):\n",
    "    #         return ' '.join(text.split())\n",
    "    #     def remove_punc(text):\n",
    "    #         exclude = set(string.punctuation)\n",
    "    #         return ''.join(ch for ch in text if ch not in exclude)\n",
    "    #     def lower(text):\n",
    "    #         return text.lower()\n",
    "    #     return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "        \n",
    "    # def get_tokens(s):\n",
    "    #     if not s: return []\n",
    "    #     return normalize_answer(s).split()\n",
    "    \n",
    "    \n",
    "    # def compute_exact(a_gold, a_pred):\n",
    "    #     return int(normalize_answer(a_gold) == normalize_answer(a_pred))\n",
    "    \n",
    "    # def compute_f1(a_gold, a_pred):\n",
    "    #     gold_toks = get_tokens(a_gold)\n",
    "    #     pred_toks = get_tokens(a_pred)\n",
    "    #     common = collections.Counter(gold_toks) & collections.Counter(pred_toks)\n",
    "    #     num_same = sum(common.values())\n",
    "    #     if len(gold_toks) == 0 or len(pred_toks) == 0:\n",
    "    #     # If either is no-answer, then F1 is 1 if they agree, 0 otherwise\n",
    "    #         return int(gold_toks == pred_toks)\n",
    "    #     if num_same == 0:\n",
    "    #         return 0\n",
    "    #     precision = 1.0 * num_same / len(pred_toks)\n",
    "    #     recall = 1.0 * num_same / len(gold_toks)\n",
    "    #     f1 = (2 * precision * recall) / (precision + recall)\n",
    "    #     return f1\n",
    "    \n",
    "    # def get_raw_scores(dataset):\n",
    "    #     exact_scores = []\n",
    "    #     f1_scores = []\n",
    "    #     for article in dataset:\n",
    "    #         gold_answers = [article[0] if normalize_answer(article[0]) else None]\n",
    "    #         if not gold_answers[0]:\n",
    "    #             print(\"sad\")\n",
    "    #             gold_answers = ['']\n",
    "    #         a_pred = article[1]\n",
    "    #         exact_scores.append(max(compute_exact(a, a_pred) for a in gold_answers))\n",
    "    #         f1_scores.append(max(compute_f1(a, a_pred) for a in gold_answers))\n",
    "    #     return exact_scores, f1_scores\n",
    "    \n",
    "    # def make_eval_dict(exact_scores, f1_scores):\n",
    "    #     total = len(exact_scores)\n",
    "    #     assert len(exact_scores) == len(f1_scores)\n",
    "    #     return collections.OrderedDict([\n",
    "    #         ('exact', 1.0 * sum(k for k in exact_scores) / total),\n",
    "    #         ('f1', 1.0 * sum(k for k in f1_scores) / total),\n",
    "    #         ('total', total),\n",
    "    #     ])\n",
    "\n",
    "    \n",
    "    # def most_similar_answer(a,answer_set):\n",
    "    #     a = a.strip().replace(' ', '')\n",
    "    #     if(a in answer_set):\n",
    "    #         return a\n",
    "    #     dis = [Levenshtein.distance(a,x) for x in answer_set]\n",
    "    #     idx = np.argmin(dis)\n",
    "    #     return answer_set[idx]\n",
    "    \n",
    "    # def evaluate_qna(dataset):\n",
    "    #     exact_raw, f1_raw = get_raw_scores(out_dict['qna'][dataset])\n",
    "    #     out_eval = make_eval_dict(exact_raw, f1_raw)\n",
    "    #     scores['qna'][dataset] = out_eval['f1'], out_eval['exact']\n",
    "        \n",
    "    #     return out_eval\n",
    "\n",
    "    # if len(out_dict['qna']['squad']) > 0:\n",
    "    #     evaluate_qna('squad')\n",
    "    # if len(out_dict['ner']['matscholar']) > 0:\n",
    "    #     evaluate('ner', 'matscholar')\n",
    "    # if len(out_dict['ner']['sofc_token']) > 0:\n",
    "    #     evaluate('ner', 'sofc_token')\n",
    "    # if len(out_dict['ner']['sc_comics']) > 0:\n",
    "    #     evaluate('ner', 'sc_comics')\n",
    "    # if len(out_dict['sar']['synthesis_actions']) > 0:\n",
    "    #     evaluate('sar', 'synthesis_actions')\n",
    "    # if len(out_dict['ee']['sc_comics']) > 0:\n",
    "    #     evaluate('ee', 'sc_comics')\n",
    "    # if len(out_dict['sf']['sofc_token']) > 0:\n",
    "    #     evaluate('sf', 'sofc_token')\n",
    "    # if len(out_dict['sc']['sofc_sent']) > 0:\n",
    "    #     evaluate_sc('sofc_sent')\n",
    "    # if len(out_dict['pc']['glass_non_glass']) > 0:\n",
    "    #     evaluate_pc('glass_non_glass')\n",
    "    # if len(out_dict['re']['structured_re']) > 0:\n",
    "    #     evaluate_re('structured_re')\n",
    "    # if len(out_dict['re']['sc_comics']) > 0:\n",
    "    #     evaluate_re('sc_comics')\n",
    "\n",
    "    # df = pd.DataFrame.from_dict({(i,j): scores[i][j] for i in scores.keys() for j in scores[i].keys()},orient='index', columns = ['micro-f1/f1', 'macro-f1/em'])\n",
    "    # df = df.apply(lambda x: 100 * round(x, 5))\n",
    "\n",
    "#     # scores.pop(('ner', 'sc_comics'))\n",
    "#     # df = pd.DataFrame(scores).apply(lambda x : 100 * round(x,5))\n",
    "#     # df = df.fillna('-')\n",
    "#     print(df.to_string())\n",
    "#     daddy_df.append(df)\n",
    "\n",
    "# df_sum = reduce(lambda x, y: x.add(y, fill_value=0), daddy_df)\n",
    "# df_mean = df_sum / len(daddy_df)\n",
    "# df_concat = pd.concat(daddy_df)\n",
    "# df_std = df_concat.groupby(df_concat.index).std()\n",
    "\n",
    "# df_mean.columns = pd.MultiIndex.from_tuples([(i, f\"mean\") for i in df_mean.columns])\n",
    "# df_std.columns = pd.MultiIndex.from_tuples([(i, f\"std\") for i in df_std.columns])\n",
    "\n",
    "# combined_df = pd.concat([df_mean, df_std], axis=1)\n",
    "# combined_df = combined_df.sort_index(axis=1).apply(lambda x : round(x,2))\n",
    "\n",
    "\n",
    "# print(f\"===eval over average of {args.num_seeds} runs===\")\n",
    "# print(combined_df.to_string())\n",
    "# prefix = args.checkpoint.split('/')[-3] + '-' + args.checkpoint.split('/')[-2]\n",
    "\n",
    "# now = datetime.datetime.now()\n",
    "# datetimestring = now.strftime(\"%y-%m-%d-%H-%M\")\n",
    "\n",
    "# combined_df.to_csv(f'/home/cse/btech/cs1200448/MatLlama/scripts/csvs/{prefix}-{datetimestring}.csv')\n",
    "\n",
    "# df_sum = reduce(lambda x, y: x.add(y, fill_value=0), daddy_df)\n",
    "# df_mean = df_sum / len(daddy_df)\n",
    "# df_concat = pd.concat(daddy_df)\n",
    "# df_std = df_concat.groupby(df_concat.index).std()\n",
    "\n",
    "# df_mean.columns = pd.MultiIndex.from_tuples([(i[0], f\"{i[1]}_mean\") for i in df_mean.columns])\n",
    "# df_std.columns = pd.MultiIndex.from_tuples([(i[0], f\"{i[1]}_std\") for i in df_std.columns])\n",
    "\n",
    "# combined_df = pd.concat([df_mean, df_std], axis=1)\n",
    "# combined_df = combined_df.sort_index(axis=1).apply(lambda x : round(x,5))\n",
    "\n",
    "\n",
    "# print(f\"===eval over average of {args.num_seeds} runs===\")\n",
    "# print(combined_df.to_string())\n",
    "\n",
    "# prefix = args.checkpoint.split('/')[-1]\n",
    "\n",
    "# now = datetime.datetime.now()\n",
    "# datetimestring = now.strftime(\"%y-%m-%d-%H-%M\")\n",
    "\n",
    "# combined_df.to_csv(f'csvs/{prefix}-{datetimestring}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
