{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b91a562d-5741-49ec-b7f2-5a9c36273a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dimensions_sem(task, pred):\n",
    "    lengths = [float(x) for x in task['output'].split('\\n')[0].split()]\n",
    "    mse = np.mean(abs(np.array(lengths) - np.array(pred[0]))/np.array(lengths))\n",
    "    angles = [float(x) for x in task['output'].split('\\n')[1].split()]\n",
    "    mae = np.mean(abs(np.array(angles) - np.array(pred[1]))/np.array(angles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0902dcb8-74a4-416b-ae0e-fdea717a7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dimensions(task, pred):\n",
    "    # task = dimensions, pred is a list\n",
    "    if \"lengths of the lattice vectors\" in task['input']:\n",
    "        lengths = [float(x) for x in task['output'].split(',')]\n",
    "        mse = np.mean(abs(np.array(lengths) - np.array(pred))/np.array(lengths))\n",
    "        return mse\n",
    "    else:\n",
    "        angles = [float(x) for x in task['output'].split(',')]\n",
    "        mae = np.mean(abs(np.array(angles) - np.array(pred))/np.array(angles))\n",
    "        return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56348dce-cb73-4470-b1bc-669d42ee6484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20d0286f-1e88-455e-ad64-d077d3288b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9330e42-9fbc-4bbf-baec-50706c4ee8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('17000_dimensions_synt_llama2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17a9823d-2a2f-49eb-aafd-5928c63d885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for lis in df.pred_cs:\n",
    "#     try:\n",
    "#         lengths = [float(x) for x in lis]\n",
    "#     except:\n",
    "#         print(lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dbc9ae1-f2a1-4180-99b7-ab970f38d629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.3, 5.6, 10.8]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965d2bbf-d5d4-4868-a406-156125ef6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/cse/btech/cs1200448/.conda/envs/llamat3_infer/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93c7a97a-d93b-4df0-9a4e-022d851407b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import collections\n",
    "from sklearn.metrics import f1_score\n",
    "import Levenshtein\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def most_similar_answer(a,answer_set):\n",
    "    a = a.strip().replace(' ', '')\n",
    "    if(a in answer_set):\n",
    "        return a\n",
    "    dis = [Levenshtein.distance(a,x) for x in answer_set]\n",
    "    idx = np.argmin(dis)\n",
    "    return answer_set[idx]\n",
    "\n",
    "def eval_atom_cnt(task, pred):\n",
    "    # task = atom count\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_dimensions(task, pred):\n",
    "    # task = dimensions, pred is a list\n",
    "    if \"lengths of the lattice vectors\" in task['input']:\n",
    "        lengths = [float(x) for x in task['output'].split(',')]\n",
    "        mse = np.mean(abs(np.array(lengths) - np.array(pred))/np.array(lengths))\n",
    "        return mse\n",
    "    else:\n",
    "        angles = [float(x) for x in task['output'].split(',')]\n",
    "        mae = np.mean(abs(np.array(angles) - np.array(pred))/np.array(angles))\n",
    "        return mae\n",
    "\n",
    "def eval_atom_name(task, pred):\n",
    "    # task = atom name\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_spacegroup(task, pred):\n",
    "    # task = space group\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_cell_volume(task, pred):\n",
    "    # task = cell_volume\n",
    "    return abs(float(task['output'])-pred)/float(task['output'])\n",
    "\n",
    "def eval_formula(task, pred):\n",
    "    # task = formula\n",
    "    return task['output']==pred\n",
    "\n",
    "def eval_replace(task, pred):\n",
    "    # task = replace\n",
    "    answer = most_similar_answer(pred, [\"Yes\", \"No\"])\n",
    "    return task['output']==answer\n",
    "\n",
    "def eval_dimensions_sem(task, pred):\n",
    "    lengths = [float(x) for x in task['output'].split('\\n')[0].split()]\n",
    "    mse = np.mean(abs(np.array(lengths) - np.array(pred[0]))/np.array(lengths))\n",
    "    angles = [float(x) for x in task['output'].split('\\n')[1].split()]\n",
    "    mae = np.mean(abs(np.array(angles) - np.array(pred[1]))/np.array(angles))\n",
    "\n",
    "    return mse, mae\n",
    "\n",
    "def eval_infill_task(task, pred):\n",
    "    return pred==task['output']\n",
    "\n",
    "def eval_gen_format(pred):\n",
    "    def trim_list(l):\n",
    "        return [x.strip().replace('\\n', '') for x in l if x]\n",
    "    l = trim_list(pred.split('\\n'))\n",
    "    l1 = trim_list(l[0].split())\n",
    "    l2 = trim_list(l[1].split())\n",
    "    if len(l1)!=3 or len(l2)!=3:\n",
    "        return 0\n",
    "    matrix = l[2:]\n",
    "    if len(matrix)%2:\n",
    "        return 0\n",
    "    for i in range(0, len(matrix), 2):\n",
    "        l1 = trim_list(matrix[i].split())\n",
    "        l2 = trim_list(matrix[i+1].split())\n",
    "        if len(l1)!=1 or len(l2)!=3:\n",
    "            return 0\n",
    "        for x in l2:\n",
    "            try:\n",
    "                y = float(x)\n",
    "            except:\n",
    "                return 0\n",
    "    return 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b6654a-012b-46d4-9bcc-a855a64ad7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "valfile = []\n",
    "with open(\"/scratch/cse/btech/cs1200448/MatLlama/ift_cif_large/val.jsonl\", 'r') as f:\n",
    "    valfile = [json.loads(line) for line in f.readlines()]\n",
    "\n",
    "out_dict = dict()\n",
    "tasks = [\"atom count\", \"dimensions_synt\", \"atom name\", \"replace\", \"space group\", \"cell_volume\", \"formula\", \"dimensions_sem\", \"vol_calc\"]\n",
    "# \"infill\", \"formula_compute\", \"conditional_generation\", \"element_generation\"\n",
    "for task in tasks:\n",
    "    out_dict[task] = []\n",
    "\n",
    "idxs = []\n",
    "for _, sample in enumerate(valfile):\n",
    "    task = sample['task']\n",
    "    system = sample['system']\n",
    "    idxs.append(_)\n",
    "    with open(f'/home/cse/btech/cs1200448/MatLlama/cif_infer_outputs_cs/{_}.txt', 'r') as f:\n",
    "        output = f.read()\n",
    "\n",
    "    if task in tasks:\n",
    "        out_dict[task].append([output, sample])\n",
    "    elif task==\"dimensions\":\n",
    "        if \"predict\" not in system and \"forecast\" not in system:\n",
    "            out_dict[\"dimensions_synt\"].append([output, sample])\n",
    "        else:\n",
    "            out_dict[\"dimensions_sem\"].append([output, sample])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da730417-ecf4-443e-98d5-67cda4f0d94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27182"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5446069-62cd-411a-bfab-8b3dab2d6f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atom name:0.2534672405547585 2091 2091\n"
     ]
    }
   ],
   "source": [
    "scores = dict()\n",
    "for task in ['atom name']:\n",
    "    print(task, end=':')\n",
    "    scores[task] = 0\n",
    "    if task==\"dimensions_sem\":\n",
    "        scores[task] = [0, 0]\n",
    "    true_cnt = 0 if (\"dimensions\" in task or \"volume\" in task) else len(out_dict[task])\n",
    "    for output, sample in out_dict[task]:\n",
    "        if task==\"atom count\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            if output.isdigit():\n",
    "                scores[task] += eval_atom_cnt(sample, int(output))\n",
    "        if task==\"dimensions_synt\":\n",
    "            l = output.split(',')\n",
    "            l = [x for x in l if x!='']\n",
    "            l = list(map(lambda x: x.strip().replace('\\n', '').replace(' ', ''), l))\n",
    "            if len(l)==3:\n",
    "                try:\n",
    "                    scores[task] += eval_dimensions(sample, [float(l[0]), float(l[1]),float(l[2])])\n",
    "                    true_cnt += 1\n",
    "                except:\n",
    "                    continue\n",
    "        if task==\"atom name\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            scores[task] += eval_atom_name(sample, output)\n",
    "        if task==\"replace\":\n",
    "            scores[task] += eval_replace(sample, output)\n",
    "        if task==\"space group\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            scores[task] += eval_spacegroup(sample, output)\n",
    "        if task==\"cell_volume\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            try:\n",
    "                answer = float(output)\n",
    "                scores[task] += eval_cell_volume(sample, answer)\n",
    "                true_cnt += 1\n",
    "            except:\n",
    "                continue\n",
    "        if task==\"formula\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            scores[task] += eval_formula(sample, output)\n",
    "        if task==\"infill\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            scores[task] += eval_infill_task(sample, output)\n",
    "        if task==\"dimensions_sem\":\n",
    "            l1 = output.split('\\n')\n",
    "            l1 = [x for x in l1 if x!='']\n",
    "            if len(l1)!=2:\n",
    "                continue\n",
    "            l21 = l1[0].split()\n",
    "            l22 = l1[1].split()\n",
    "            l21 = [x.strip() for x in l21 if x!='']\n",
    "            l22 = [x.strip() for x in l22 if x!='']\n",
    "            if len(l21)==3 and len(l22)==3:\n",
    "                mse, mae = eval_dimensions_sem(sample, [[float(l21[0]), float(l21[1]),float(l21[2])], [float(l22[0]), float(l22[1]), float(l22[2])]])\n",
    "                true_cnt += 1\n",
    "                scores[task][0] += mse\n",
    "                scores[task][1] += mae\n",
    "        if task==\"vol_calc\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            try:\n",
    "                answer = float(output)\n",
    "                scores[task] += eval_cell_volume(sample, answer)\n",
    "                true_cnt += 1\n",
    "            except:\n",
    "                continue \n",
    "        if task==\"formula_compute\":\n",
    "            output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "            scores[task] += eval_formula(sample, output)\n",
    "        if \"generation\" in task:\n",
    "            scores[task] += eval_gen_format(output)\n",
    "        \n",
    "    if \"dimensions_sem\" not in task:\n",
    "        scores[task] /= true_cnt\n",
    "    else:\n",
    "        scores[task][0] /= true_cnt\n",
    "        scores[task][1] /= true_cnt\n",
    "\n",
    "    print(scores[task], true_cnt, len(out_dict[task]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34486521-14fe-47a5-a68b-279e9976a5af",
   "metadata": {},
   "source": [
    "<h2>dimensions_sem</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c100ac30-0cca-4e36-8927-8f7d1ead1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'dimensions_sem'\n",
    "df1k = pd.read_csv(f'1000_{task}_llama3.csv')\n",
    "df15k = pd.read_csv(f'15000_{task}_llama3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "89592bee-9628-4118-af0f-3387dfaef9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers(s):\n",
    "    # Use regex to find floating-point numbers\n",
    "    result = re.findall(r'\\d+\\.\\d+|\\d+', s)\n",
    "    # Join the result list into a single string\n",
    "    return float(''.join(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29b9b866-3174-4602-b81f-dde243b50187",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cnt = 0\n",
    "scores = dict()\n",
    "\n",
    "scores[task] = [0, 0]\n",
    "for i in range(len(df1k)):\n",
    "\n",
    "    sample = {'output':df1k.actual.iloc[i], 'input':df15k.input.iloc[i]}\n",
    "    output = df1k.pred_cs.iloc[i]\n",
    "    l1 = output.split('\\n')\n",
    "    l1 = [x for x in l1 if x!='']\n",
    "    if len(l1)!=2:\n",
    "        continue\n",
    "    l21 = l1[0].split()\n",
    "    l22 = l1[1].split()\n",
    "    l21 = [x.strip() for x in l21 if x!='']\n",
    "    l22 = [x.strip() for x in l22 if x!='']\n",
    "    # print(l22)\n",
    "    if len(l21)==3 and len(l22)==3:\n",
    "        mse, mae = eval_dimensions_sem(sample, [[float(l21[0]), float(l21[1]),float(l21[2])], [float(l22[0]), float(l22[1]), float(extract_numbers(l22[2]))]])\n",
    "        true_cnt += 1\n",
    "        scores[task][0] += mse\n",
    "        scores[task][1] += mae\n",
    "    else:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f90b359-13ff-44b2-9d71-2023371889f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimensions_sem': [88.03136787216347, 120.99035484565152]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "208a96e8-6de8-4034-9598-a8d158698448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.042100128107203955, 0.05786243655937424)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[task][0]/len(df1k), scores[task][1]/len(df1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbabfc94-31a7-4b81-bd07-a509db2fd702",
   "metadata": {},
   "source": [
    "<h2>vol_calc</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1d08d2a7-5d6c-43ad-a8ae-c7858c233213",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'vol_calc'\n",
    "df1k = pd.read_csv(f'1000_{task}_llama3.csv')\n",
    "df15k = pd.read_csv(f'15000_{task}_llama3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "99aee9f6-fc2c-491f-aee4-59aa564a7246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_numbers(s):\n",
    "    # Use regex to find floating-point numbers\n",
    "    result = re.findall(r'\\d+\\.\\d+|\\d+', s)\n",
    "    # Join the result list into a single string\n",
    "    return float(''.join(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d602352b-0f14-4d27-8857-0c5f1d5a6804",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cnt = 0\n",
    "scores = dict()\n",
    "\n",
    "scores[task] = 0\n",
    "for i in range(len(df1k)):\n",
    "\n",
    "    sample = {'output':df1k.actual.iloc[i], 'input':df15k.input.iloc[i]}\n",
    "    output = df1k.pred_cs.iloc[i]\n",
    "    # output = output.split('Title')[0]\n",
    "    # output = extract_numbers(output)\n",
    "    try:\n",
    "        answer = float(output)\n",
    "        scores[task] += eval_cell_volume(sample, answer)\n",
    "        true_cnt += 1\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa6b79f2-bc52-49d3-b2a6-755d50441654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vol_calc': 27.402442642897732}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b39885f-cda8-4c41-8815-67a3e28f61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "36d45ebd-e021-4398-b8f1-c6bf13a244d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9970438392499362\n",
      "5.71646775539933\n",
      "212.70589630630772\n",
      "0.9995139077623317\n",
      "3.0016779670636065\n",
      "34.97600226866867\n"
     ]
    }
   ],
   "source": [
    "for func in [r2_score, mean_absolute_error, mean_squared_error]:\n",
    "    print(func(df1k.actual, df1k.pred_cs))\n",
    "\n",
    "for func in [r2_score, mean_absolute_error, mean_squared_error]:\n",
    "    print(func(df15k.actual, df15k.pred_cs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fe36c92a-4396-43da-940e-4e8dd3d3b3d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.042100128107203955, 0.05786243655937424)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[task][0]/len(df1k), scores[task][1]/len(df1k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e938ac67-09b1-4e5e-9537-8eb3461c8ab1",
   "metadata": {},
   "source": [
    "<h2>cell_volume</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "716262e9-cbfe-4956-a490-34eca65818c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'cell_volume'\n",
    "df1k = pd.read_csv(f'15000_{task}_llama3.csv')\n",
    "df15k = pd.read_csv(f'15000_{task}_llama3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1ca5ab56-cf83-4469-a4e7-da39b19d0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cnt = 0\n",
    "scores = dict()\n",
    "\n",
    "scores[task] = 0\n",
    "for i in range(len(df1k)):\n",
    "    # if task==\"cell_volume\":\n",
    "    output = str(df1k.pred_cs.iloc[i])\n",
    "    output = output.strip().replace('\\n', '').replace(' ', '')\n",
    "    sample = {'output':df1k.actual.iloc[i], 'input':df15k.input.iloc[i]}\n",
    "    try:\n",
    "        answer = float(output)\n",
    "        scores[task] += eval_cell_volume(sample, answer)\n",
    "        true_cnt += 1\n",
    "    except Exception as e:\n",
    "        print(i,e)\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fddf9169-68b8-4d38-ba90-c398030919a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cell_volume': 0.0}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ea3a6f-814d-4519-a323-dc8aa1aa048d",
   "metadata": {},
   "source": [
    "<h2>dimensions_synt</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b0a3ee35-e059-42d5-aecb-5c3e33bb30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cnt = 0\n",
    "scores = dict()\n",
    "\n",
    "scores[task] = 0\n",
    "for i in range(len(df1k)):\n",
    "    output = df1k.pred_cs.iloc[i]\n",
    "    \n",
    "    l = output.split(',')\n",
    "    l = [x for x in l if x!='']\n",
    "    l = list(map(lambda x: x.strip().replace('\\n', '').replace(' ', ''), l))\n",
    "    sample = {'output':df1k.actual.iloc[i], 'input':df15k.input.iloc[i]}\n",
    "    \n",
    "    if len(l)==3:\n",
    "        try:\n",
    "            scores[task] += eval_dimensions(sample, [float(l[0]), float(l[1]),float(l[2])])\n",
    "            true_cnt += 1\n",
    "        except Exception as e:\n",
    "            print(i, e)\n",
    "            # continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e297ce-0f6a-448b-b6f8-d1e6c577fac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002874286991686685"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores[task]/2091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d6c9f-0558-45bb-b248-1104081cf6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
