{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3b70c7-25ff-4765-85cd-3b9c674a80a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "valfile = \"/home/cse/btech/cs1200389/MatLlama/MatLLaMA/datasets/downstream/val/val.jsonl\"\n",
    "def load_jsonl(path):\n",
    "    with open(path, 'r') as f:\n",
    "        a = f.readlines()\n",
    "        g = [json.loads(i) for i in a]\n",
    "    return g\n",
    "val_ds = load_jsonl(valfile)\n",
    "doping_test = load_jsonl('/home/cse/btech/cs1200389/MatLlama/MatLLaMA/datasets/ift/final_ift/doping_test.jsonl')\n",
    "mof1_test = load_jsonl('/home/cse/btech/cs1200389/MatLlama/MatLLaMA/datasets/ift/final_ift/mof1_test.jsonl')\n",
    "mof2_test = load_jsonl('/home/cse/btech/cs1200389/MatLlama/MatLLaMA/datasets/ift/final_ift/mof2_test.jsonl')\n",
    "with open(\"/home/cse/btech/cs1200389/MatLlama/MatLLaMA/datasets/ift/final_ift/discomat_dense_test.jsonl\", 'r') as f:\n",
    "    discomat_test = [json.loads(line) for line in f.readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e5cb9c-75e8-466c-bb6e-0280973bebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ['http_proxy'] =\"10.10.78.22:3128\"\n",
    "# os.environ['https_proxy'] =\"10.10.78.22:3128\"\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key = \"YOUR API KEY\"\n",
    "  # organization='IITD',\n",
    "  # project='',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f94b4e0-40f2-480e-ba35-23c51a2d0d27",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4_val\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Connection error.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_transports/default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_transports/default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpcore/_sync/http_proxy.py:317\u001b[0m, in \u001b[0;36mTunnelHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_tls\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[0;32m--> 317\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpcore/_sync/http11.py:383\u001b[0m, in \u001b[0;36mHTTP11UpgradeStream.start_tls\u001b[0;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_tls\u001b[39m(\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    379\u001b[0m     ssl_context: ssl\u001b[38;5;241m.\u001b[39mSSLContext,\n\u001b[1;32m    380\u001b[0m     server_hostname: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    381\u001b[0m     timeout: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    382\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NetworkStream:\n\u001b[0;32m--> 383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_tls\u001b[49m\u001b[43m(\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpcore/_backends/sync.py:152\u001b[0m, in \u001b[0;36mSyncStream.start_tls\u001b[0;34m(self, ssl_context, server_hostname, timeout)\u001b[0m\n\u001b[1;32m    148\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    149\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[1;32m    151\u001b[0m }\n\u001b[0;32m--> 152\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mtry\u001b[39;49;00m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpcore/_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[0;34m(map)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[0;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:952\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 952\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_transports/default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    231\u001b[0m )\n\u001b[0;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/contextlib.py:155\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen\u001b[38;5;241m.\u001b[39mthrow(typ, value, traceback)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/httpx/_transports/default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mConnectError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1006)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m outname \u001b[38;5;241m=\u001b[39m model_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_val\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(outname)\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mget_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m19\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madditional\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m. Do not output any additional text. and give proper parseable json format when asked for it\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m, in \u001b[0;36mget_output\u001b[0;34m(input_dict, additional)\u001b[0m\n\u001b[1;32m      9\u001b[0m sys \u001b[38;5;241m=\u001b[39m sys \u001b[38;5;241m+\u001b[39m additional\n\u001b[1;32m     10\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: sys},\n\u001b[1;32m     12\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}\n\u001b[1;32m     13\u001b[0m ]\n\u001b[0;32m---> 14\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\n\u001b[1;32m     20\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m response_text \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response_text\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:976\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    973\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:976\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    973\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered Exception\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    975\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 976\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    985\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:1053\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m-> 1053\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/site-packages/openai/_base_client.py:986\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[1;32m    977\u001b[0m             options,\n\u001b[1;32m    978\u001b[0m             cast_to,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    982\u001b[0m             response_headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    983\u001b[0m         )\n\u001b[1;32m    985\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaising connection error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 986\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIConnectionError(request\u001b[38;5;241m=\u001b[39mrequest) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m    988\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHTTP Response: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%i\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    990\u001b[0m     request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m     response\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    995\u001b[0m )\n\u001b[1;32m    996\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx-request-id\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[0;31mAPIConnectionError\u001b[0m: Connection error."
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4\"\n",
    "def get_prompt(input_dict):\n",
    "    system_prompt = input_dict['system']\n",
    "    prompt = input_dict['question']\n",
    "    return system_prompt, prompt\n",
    "\n",
    "def get_output(input_dict, additional = \"\"):\n",
    "    sys, prompt = get_prompt(input_dict)\n",
    "    sys = sys + additional\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": sys},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,  \n",
    "        messages=messages,\n",
    "        temperature=0.0,\n",
    "        max_tokens=2000,\n",
    "        frequency_penalty=0.0\n",
    "    )\n",
    "    response_text = response.choices[0].message.content\n",
    "    return response_text\n",
    "\n",
    "outname = model_name + \"_val\"\n",
    "print(outname)\n",
    "print(get_output(val_ds[19], additional = \". Do not output any additional text. and give proper parseable json format when asked for it\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb14858-26d9-4ad0-8de4-659954efc874",
   "metadata": {},
   "source": [
    "## Downstream run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f1703be-b353-45fe-b23f-1a7282aed71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downstream_outs = sorted(downstream_outputs, key = lambda x : x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da2ff17f-90ba-4b1e-aa04-79221e904770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual = [downstream_outs[0]]\n",
    "# for i in range(1,len(downstream_outs)):\n",
    "#     if(downstream_outs[i-1][0] == downstream_outs[i][0]):\n",
    "#         actual[-1] = downstream_outs[i]\n",
    "#     else:\n",
    "#         actual.append(downstream_outs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30982db-1315-47ad-ab34-6c5471e59449",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6181e32f-e75d-4018-bb5a-a9918e908735",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import threading \n",
    "from threading import Thread\n",
    "downstream_outputs = {}\n",
    "def get_downstream_outputs_range(start_idx, end_idx):\n",
    "    exceptions = []\n",
    "    start_time = time.time()\n",
    "    downstream_outputs[start_idx] = []\n",
    "    # for idx in tqdm(range(5001,len(val_ds))):\n",
    "    idx = start_idx\n",
    "    failures = 0\n",
    "    print(f\"from idx = {idx} to {end_idx}\")\n",
    "    while idx < end_idx:\n",
    "        try:\n",
    "            out = get_output(val_ds[idx], additional = \". Do not output any additional text. and give proper parseable json format when asked for it\")\n",
    "            downstream_outputs[start_idx].append((idx, out))\n",
    "            idx += 1\n",
    "            failures = 0 #resetting failures.\n",
    "            print(\"success for \", idx, \" rate = \", (time.time() - start_time)/(idx), end = \"          \\r\")\n",
    "        except Exception as e:\n",
    "            print(\"failed at \", idx, \" because\\n\", e)\n",
    "            failures += 1\n",
    "            if(failures >= 6):\n",
    "                downstream_outputs[start_idx].append((idx, \"\")) \n",
    "                print(f\"IDX {idx} failed to calculate, setting to ''\")\n",
    "                failures = 0\n",
    "                idx += 1\n",
    "            else:\n",
    "                time.sleep(4)\n",
    "                continue    #sleep and then redo the same index.\n",
    "        if(idx % 1000 == 0):\n",
    "            with open(outname + f\"_downstream_{start_idx}_{end_idx}.pkl\", \"wb\") as f:\n",
    "                pickle.dump(downstream_outputs[start_idx], f) #saving every 1000 iterations incase something goes wrong and generation has to stop in the middle.\n",
    "    with open(outname + f\"_downstream_{start_idx}_{end_idx}.pkl\", \"wb\") as f:\n",
    "        pickle.dump(downstream_outputs[start_idx], f)\n",
    "    print(f\"total time taken for {start_idx} to {end_idx} is {time.time() - start_time}\")\n",
    "    return downstream_outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b60460-ffef-4088-a8ba-d9c65ae2943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 3085, 6171, 9256, 12342]\n"
     ]
    }
   ],
   "source": [
    "all_outputs = []\n",
    "partitions = 4 \n",
    "overall_len = len(val_ds)\n",
    "indices = []\n",
    "for i in range(partitions+1):\n",
    "    indices.append((i * overall_len)//partitions)\n",
    "\n",
    "print(indices)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8ecdfd2-ca1c-4737-a710-bee8907b187e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from idx = 0 to 3085\n",
      "from idx = 3085 to 6171\n",
      "from idx = 6171 to 9256\n",
      "from idx = 9256 to 12342\n",
      "failed at  6210  because=  0.015695978170153738            \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29565, Requested 2573. Please try again in 4.276s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6210  because 1.4867912327370993              \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28065, Requested 2573. Please try again in 1.276s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9309  because 1.5168125527970335              \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28205, Requested 2365. Please try again in 1.14s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6210  because\n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29804, Requested 2573. Please try again in 4.754s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  50  becausee =  0.008253339742464482          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27733, Requested 2595. Please try again in 656ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3155  because\n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29656, Requested 2558. Please try again in 4.428s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6212  because=  0.008888037663357818          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28080, Requested 2433. Please try again in 1.026s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3155  because 1.646535924836701          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27649, Requested 2558. Please try again in 414ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  58  becausee =  0.031187029192816726          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27795, Requested 2313. Please try again in 216ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9324  because=  0.015996488446874766          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27664, Requested 2425. Please try again in 178ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6218  because 1.648650246606746               \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27854, Requested 2459. Please try again in 626ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9326  because 1.6131588785271895             \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27562, Requested 4186. Please try again in 3.496s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3180  because 1.5379086101756376              \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27706, Requested 2511. Please try again in 434ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9326  because=  0.022858016642434607          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27384, Requested 4186. Please try again in 3.14s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6234  because 1.532153961609821               \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29421, Requested 2120. Please try again in 3.082s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  102  because =  0.016796290005459794          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29849, Requested 2129. Please try again in 3.956s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3191  because\n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29619, Requested 2360. Please try again in 3.958s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3193  because=  0.02749003813816951           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27936, Requested 2209. Please try again in 290ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6245  because=  0.05610792749480676           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28529, Requested 2115. Please try again in 1.288s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9336  because=  0.056521460427907004          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28648, Requested 2173. Please try again in 1.642s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  113  because =  0.0573062650936166           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27792, Requested 4174. Please try again in 3.932s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9338  because=  0.030617622275711767          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27632, Requested 2450. Please try again in 164ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  113  because =  0.03152243891812148           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27678, Requested 4174. Please try again in 3.704s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3209  because=  0.021581674609694124          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27939, Requested 2235. Please try again in 348ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  113  because =  0.022114493497988073          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29042, Requested 4174. Please try again in 6.432s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  113  because =  0.06901651419160233           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29467, Requested 4174. Please try again in 7.282s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6277  because=  0.024685874665758306          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28813, Requested 2271. Please try again in 2.168s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9359  because=  0.07326245455504275           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27899, Requested 2417. Please try again in 632ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  122  because =  0.027501518716933265          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29875, Requested 2600. Please try again in 4.95s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3255  because=  0.0425598207781294            \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27728, Requested 2283. Please try again in 22ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9372  because  2.145773931155129             \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29483, Requested 2526. Please try again in 4.017s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  133  because =  0.04527901011171273           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27308, Requested 2756. Please try again in 128ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  133  because =  0.09031192896418583           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27491, Requested 2756. Please try again in 494ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6312  because=  0.03206362676534091           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27805, Requested 2845. Please try again in 1.3s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9386  because=  0.09261472165657164           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27868, Requested 2406. Please try again in 548ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6312  because  2.295776489955276            \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27824, Requested 2845. Please try again in 1.338s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  138  because =  0.04970917635263051          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28539, Requested 2227. Please try again in 1.532s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9386  because=  0.0499507620895277          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28046, Requested 2406. Please try again in 904ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9386  because=  0.05070348555528665           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29807, Requested 2406. Please try again in 4.426s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  138  because =  0.03476447630858185           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29690, Requested 2227. Please try again in 3.834s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6329  because=  0.03527641920864684           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29705, Requested 2347. Please try again in 4.104s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3307  because=  0.05382836329961452           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29418, Requested 2553. Please try again in 3.941s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9400  because  2.474788008417402             \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27451, Requested 2969. Please try again in 840ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  3307  because=  0.0557981664292842            \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27866, Requested 2553. Please try again in 838ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9400  because=  0.05635393866032188           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27587, Requested 2969. Please try again in 1.112s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  151  because =  0.10941143185755896          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28649, Requested 2328. Please try again in 1.954s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  6348  because\n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28592, Requested 2380. Please try again in 1.944s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  9405  because=  0.11258572714340284           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27983, Requested 2480. Please try again in 926ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  157  because =  0.05892766276207367          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27765, Requested 2707. Please try again in 943ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  157  because =  0.11473403093256482          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27543, Requested 2707. Please try again in 500ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "success for  3327  rate =  0.1166962207814828            \r"
     ]
    }
   ],
   "source": [
    "threads = [0]*partitions\n",
    "# downstream_outputs = {}\n",
    "for i in range(partitions):\n",
    "    threads[i] = Thread(target = get_downstream_outputs_range, args = (indices[i], indices[i+1]))\n",
    "for i in range(partitions):\n",
    "    threads[i].start()\n",
    "# for i in range(partitions):\n",
    "    # threads[i].join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2dc0fde5-b5b0-47e1-84ce-c59f0451f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3086\n"
     ]
    }
   ],
   "source": [
    "print(len(downstream_outputs[indices[3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a766845f-fa1b-4431-b7ae-a5bda5d048cd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed at  7  becausete =  0.0007215210435167935           \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27947, Requested 2337. Please try again in 568ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  4938  because1.1729172468185425                \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28342, Requested 2143. Please try again in 970ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  8  becausete =  0.0012470555066652269          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 28507, Requested 2258. Please try again in 1.53s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  7408  because1.7627663877275255                \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29599, Requested 2414. Please try again in 4.026s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  2483  because=  0.0037740766961902933          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27571, Requested 2614. Please try again in 370ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  4951  because=  0.0030408037404108853          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 27719, Requested 2298. Please try again in 34ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "failed at  15  becausee =  0.0069458036020310894          \n",
      " Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-429Lb6AirfSQULQ31VuPqF03 on tokens per min (TPM): Limit 30000, Used 29737, Requested 2469. Please try again in 4.412s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "success for  16  rate =  2.417079880833626                \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(partitions):\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mthreads\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m actual_outputs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m downstream_outputs:\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/threading.py:1112\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1112\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1114\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m/home/cse/btech/cs1200389/.conda/envs/matllama2.0/lib/python3.11/threading.py:1132\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1133\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(partitions):\n",
    "    threads[i].join()\n",
    "actual_outputs = []\n",
    "for key in downstream_outputs:\n",
    "    actual_outputs.extend(downstream_outputs[key])\n",
    "actual_outputs = sorted(actual_outputs, key = lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bca41f28-47a4-4de4-b7f3-d1de63c42404",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(partitions):\n",
    "    threads[i].join()\n",
    "actual_outputs = []\n",
    "for key in downstream_outputs:\n",
    "    actual_outputs.extend(downstream_outputs[key])\n",
    "actual_outputs = sorted(actual_outputs, key = lambda x: x[0])\n",
    "\n",
    "with open(outname + \"_downstream_full.pkl\", \"wb\") as f:\n",
    "    pickle.dump(actual_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e0696b1-2dc9-43bc-874a-60980358cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12342"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(actual_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a68e42b-98c7-4374-a734-73a76ffeabfa",
   "metadata": {},
   "source": [
    "## SIE Doping mof1 mof2 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cbeb4845-ff8c-4ca4-aa87-c6a840d84e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at index  232  at time:  449.8146598339081 rate =  1.938856300608865 s/out     \r"
     ]
    }
   ],
   "source": [
    "doping_outputs = []\n",
    "exceptions = []\n",
    "import time\n",
    "# for idx in tqdm(range(len(doping_test))):\n",
    "idx = 0\n",
    "start = time.time()\n",
    "failures = 0\n",
    "while(idx < len(doping_test)):\n",
    "    try:\n",
    "        out = get_output(doping_test[idx], additional = \".Do not output any additional text\")\n",
    "        doping_outputs.append((idx, out))\n",
    "        idx += 1\n",
    "        print(\"at index \", idx, \" at time: \", time.time() - start, \"rate = \", (time.time() -start)/idx, \"s/out\", end = \"   \\r\")\n",
    "        failures = 0\n",
    "    except Exception as e:\n",
    "        print(\"failed at \", idx, \" because\\n\", e)\n",
    "        exceptions.append((idx, e))\n",
    "        failures += 1\n",
    "        if(failures >= 6):\n",
    "            failures = 0\n",
    "            doping_outputs.append((idx,\"\"))\n",
    "            idx += 1\n",
    "            print(f\"setting {idx} to ''\\n\")\n",
    "        time.sleep(1);\n",
    "        # No updating the idx incase we encounter an error because it is likely a rate limit error.  \n",
    "with open(outname + \"_doping.pkl\", \"wb\") as f:\n",
    "    pickle.dump(doping_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36270331-84cc-40b0-858a-e81f7df55156",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at index  61  at time:  267.25453758239746 rate =  0.2282468248093451    \r"
     ]
    }
   ],
   "source": [
    "mof1_outputs = []\n",
    "exceptions = []\n",
    "idx = 0;\n",
    "start = time.time()\n",
    "failures = 0\n",
    "while(idx < len(mof1_test)):\n",
    "    print(\"at index \", idx, \" at time: \", time.time() - start, \"rate = \", (idx/(time.time() -start)), end = \"   \\r\")\n",
    "    try:\n",
    "        out = get_output(mof1_test[idx],additional = \".Do not output any additional text\")\n",
    "        mof1_outputs.append((idx, out))\n",
    "        idx += 1\n",
    "        failures = 0\n",
    "    except Exception as e:\n",
    "        print(\"failed at \", idx, \" because\\n\", e)\n",
    "        failures += 1\n",
    "        if(failures > 5):\n",
    "            failures = 0\n",
    "            print(\"setting \", idx, \" to ''\")\n",
    "            mof1_outputs.append((idx, ''))\n",
    "            idx += 1\n",
    "        exceptions.append((idx, e))\n",
    "        time.sleep(3)\n",
    "with open(outname + \"_mof1.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mof1_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5166593-2799-4f6b-9da7-61dc1c4fe7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"../llamat2_chat_train_2epochs_full_ex_mof1_test.pkl\", \"rb\") as f:\n",
    "#     check= pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4495de0b-1a0f-4d0f-b215-344b77b41522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at index  50  at time:  135.9889795780182 rate =  0.36767684873573575    \r"
     ]
    }
   ],
   "source": [
    "mof2_outputs = []\n",
    "exceptions = []\n",
    "idx = 0;\n",
    "failures = 0\n",
    "start = time.time()\n",
    "while(idx < len(mof2_test)):\n",
    "    print(\"at index \", idx, \" at time: \", time.time() - start, \"rate = \", (idx/(time.time() -start)), end = \"   \\r\")\n",
    "    try:\n",
    "        out = get_output(mof2_test[idx],additional = \"do not output any additional text\")\n",
    "        mof2_outputs.append((idx, out))\n",
    "        idx += 1\n",
    "        failures = 0\n",
    "    except Exception as e:\n",
    "        print(\"failed at \", idx, \" because\\n\", e)\n",
    "        failures += 1\n",
    "        if(failures > 5):\n",
    "            failures = 0\n",
    "            print(\"setting \", idx, \" to ''\")\n",
    "            mof2_outputs.append((idx, ''))\n",
    "            idx += 1\n",
    "        exceptions.append((idx, e))\n",
    "with open(outname + \"_mof2.pkl\", \"wb\") as f:\n",
    "    pickle.dump(mof2_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdbad3-c4f5-448e-bc84-ea0c846a2ebf",
   "metadata": {},
   "source": [
    "## Discomat run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "412dba76-78bd-4e9c-aca4-e9f65bb1cb0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at index  736  at time:  1392.2432568073273 rate =  0.5286432492260569   \r"
     ]
    }
   ],
   "source": [
    "discomat_outputs = []\n",
    "idx = 0;\n",
    "start = time.time()\n",
    "failures = 0\n",
    "while(idx < len(discomat_test)):\n",
    "    print(\"at index \", idx, \" at time: \", time.time() - start, \"rate = \", (idx/(time.time() -start)), end = \"   \\r\")\n",
    "    try:\n",
    "        out = get_output(discomat_test[idx],additional = \"do not output any additional text\")\n",
    "        discomat_outputs.append((idx, out))\n",
    "        idx += 1\n",
    "        failures = 0\n",
    "    except Exception as e:\n",
    "        print(\"failed at \", idx, \" because\\n\", e)\n",
    "        failures += 1\n",
    "        if(failures > 5):\n",
    "            failures = 0\n",
    "            print(\"setting \", idx, \" to ''\")\n",
    "            discomat_outputs.append((idx, ''))\n",
    "            idx += 1\n",
    "        exceptions.append((idx, e))\n",
    "with open(outname + \"_discomat.pkl\", \"wb\") as f:\n",
    "    pickle.dump(discomat_outputs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abc4744-f9d1-43e6-922c-59f4f76f7641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ae40de-358e-49b1-a647-6b9954cfc493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
