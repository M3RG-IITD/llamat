{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb0d7bd-59fd-48e6-9101-33753fc1826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import  pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c575c5b-8efd-435b-8b4f-7106ea6f430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es = pd.read_csv('corpus_priority.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1cbd5e2-d152-41b6-b9ea-a6dc2304a4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_es_1 = df_es[df_es.priority_zaki==1]\n",
    "df_es_2 = df_es[df_es.priority_zaki==2]\n",
    "df_es_3 = df_es[df_es.priority_zaki==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "167ddd85-1fa3-4e92-956c-12b93192a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch/civil/phd/cez198233/vaibhav_nlp/corpus/'\n",
    "path2 = '/scratch/cse/btech/cs1200448/MatLlama/redP_split/train.json'\n",
    "# output_path = '/scratch/cse/btech/cs1200448/MatLlama/new_ds_plain'\n",
    "output_path = '/scratch/civil/phd/cez198233/vaibhav_nlp/corpus/corpus_training/'\n",
    "files = list(map(lambda x: path+'elsevier/'+x, os.listdir(path+'elsevier/')))\n",
    "files += list(map(lambda x: path+'springer/'+x, os.listdir(path+'springer/')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47668033-429b-48dc-951a-341f5ad578b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_1 = path + df_es_1['publisher'] + '/' + df_es_1['journal'] + '.pkl'\n",
    "files_2 = path + df_es_2['publisher'] + '/' + df_es_2['journal'] + '.pkl'\n",
    "files_3 = path + df_es_3['publisher'] + '/' + df_es_3['journal'] + '.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e1fd3b4-6e46-4165-b5fb-2bcb31ff6592",
   "metadata": {},
   "outputs": [],
   "source": [
    "springer =  ['Atomic_Energy', 'Adsorption', 'Applied_Composite_Materials', 'Chemical_and_Petroleum_Engineering', 'Fibers_and_Polymers', 'Frontiers_of_Structural_and_Civil_Engineering', 'Glass_and_Ceramics', 'Inorganic_Materials', 'International_Journal_of_Precision_Engineering_and_Manufacturing', 'Journal_of_Solid_State_Electrochemistry', 'Journal_of_Superconductivity', 'Rare_Metals']\n",
    "elsevier = ['Acta_Materialia', 'Additive_Manufacturing', 'Atomic_Data_and_Nuclear_Data_Tables', 'Ceramics_International', 'Chemical_Engineering_and_Processing_-_Process_Intensification', 'Corrosion_Science', 'Energy_Storage_Materials', 'Materials_Chemistry_and_Physics','Materials_Letters', 'Optical_Materials', 'Progress_in_Solid_State_Chemistry', 'Scripta_Materialia', 'Zeolites', 'Journal_of_Non-Crystalline_Solids','Journal_of_Molecular_Structure'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "266777ab-162f-4e2f-96d7-28deb771a443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(484, 262, 59)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files_1), len(files_2), len(files_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4bf3e2d8-a211-4da6-a0fd-e463ae7f7f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:25<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 945868 404974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 945868/945868 [36:33<00:00, 431.20it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 404974/404974 [20:13<00:00, 333.72it/s]\n"
     ]
    }
   ],
   "source": [
    "random.seed(0)\n",
    "\n",
    "for priority, files in zip([1],[files_1]):#, files_3]):\n",
    "    files = [file for file in files if file.endswith('pkl')]\n",
    "    \n",
    "    train_ds = []\n",
    "    val_ds = []\n",
    "\n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "\n",
    "    for pkl in tqdm(files[50:50]):\n",
    "        # if pkl.split('.')[0].split('/')[-1] not in elsevier:\n",
    "        #     if pkl.split('.')[0].split('/')[-1] not in springer:\n",
    "        #         continue\n",
    "        with open(pkl, 'rb') as f:\n",
    "            txts = pickle.load(f)\n",
    "            for document in txts:\n",
    "                x = random.random()\n",
    "                if x < 0.7:\n",
    "                    cnt1 += 1\n",
    "                    train_ds.append(txts[document])\n",
    "                else:\n",
    "                    cnt2 += 1\n",
    "                    val_ds.append(txts[document])\n",
    "    print(priority, cnt1, cnt2)\n",
    "    with open(os.path.join(output_path, f'train_priority_0_50_{priority}.json'), \"w\") as f:\n",
    "        for txt in tqdm(train_ds):\n",
    "            doc = {\"text\": txt}\n",
    "            f.write(json.dumps(doc) + \"\\n\")\n",
    "    with open(os.path.join(output_path, f'val_priority_0_50_{priority}.json'), \"w\") as f:\n",
    "        for txt in tqdm(val_ds):\n",
    "            doc = {\"text\": txt}\n",
    "            f.write(json.dumps(doc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5024def-0d70-4b33-aa08-13e779b0780b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9541371-aa16-49f4-9a11-0f3b452c3ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 59/59 [00:19<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 160419 68645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 160419/160419 [00:26<00:00, 5959.96it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 68645/68645 [00:11<00:00, 6038.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# random.seed(0)\n",
    "\n",
    "for priority, files in zip([3],[files_3]):#, files_3]):\n",
    "    files = [file for file in files if file.endswith('pkl')]\n",
    "    \n",
    "    train_ds = []\n",
    "    val_ds = []\n",
    "\n",
    "    cnt1 = 0\n",
    "    cnt2 = 0\n",
    "\n",
    "    for pkl in tqdm(files):\n",
    "        # if pkl.split('.')[0].split('/')[-1] not in elsevier:\n",
    "        #     if pkl.split('.')[0].split('/')[-1] not in springer:\n",
    "        #         continue\n",
    "        with open(pkl, 'rb') as f:\n",
    "            txts = pickle.load(f)\n",
    "            for document in txts:\n",
    "                x = random.random()\n",
    "                if x < 0.7:\n",
    "                    cnt1 += 1\n",
    "                    train_ds.append(txts[document])\n",
    "                else:\n",
    "                    cnt2 += 1\n",
    "                    val_ds.append(txts[document])\n",
    "    print(priority, cnt1, cnt2)\n",
    "    with open(os.path.join(output_path, f'ctrain_priority_{priority}.json'), \"w\") as f:\n",
    "        for txt in tqdm(train_ds):\n",
    "            doc = {\"text\": txt}\n",
    "            f.write(json.dumps(doc) + \"\\n\")\n",
    "    with open(os.path.join(output_path, f'cval_priority_{priority}.json'), \"w\") as f:\n",
    "        for txt in tqdm(val_ds):\n",
    "            doc = {\"text\": txt}\n",
    "            f.write(json.dumps(doc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af74572e-f790-4713-8af3-5948d18beb3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234486"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5176d4c0-b609-4019-8c17-7f27187c413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 651356/651356 [00:11<00:00, 54839.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32590/32590 [00:01<00:00, 31894.34it/s]\n"
     ]
    }
   ],
   "source": [
    "redp_sampled = []\n",
    "with open(path2, 'r') as f:\n",
    "    l = f.readlines()\n",
    "    for line in tqdm(l):\n",
    "        x = json.loads(line)\n",
    "        y = random.random()\n",
    "        if y < 0.05:\n",
    "            redp_sampled.append(x['text'])\n",
    "with open(os.path.join(output_path, 'redp_sampled.json'), \"w\") as f:\n",
    "    for txt in tqdm(redp_sampled):\n",
    "        doc = {\"text\": txt}\n",
    "        f.write(json.dumps(doc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ae2c91e-8a9a-4fdb-ba6f-ed16b26926c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_ds = []\n",
    "cnt1 = 0\n",
    "cnt2 = 0\n",
    "width1 = 1000\n",
    "width2 = 220\n",
    "while cnt1 < len(train_ds):\n",
    "    for j in range(cnt1, cnt1+width1):\n",
    "        if j<len(train_ds):\n",
    "            inter_ds.append(train_ds[j])\n",
    "    for j in range(cnt2, cnt2+width2):\n",
    "        if j<len(redp_sampled):\n",
    "            inter_ds.append(redp_sampled[j])\n",
    "    cnt1 += width1\n",
    "    cnt2 += width2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4c73fa2-337a-40fb-adc7-f3e5f5a7a615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178440"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inter_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64366280-79fc-499c-a3f1-2fdeacb23626",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 178440/178440 [00:17<00:00, 10314.98it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(os.path.join('/scratch/cse/btech/cs1200448/MatLlama/new_ds_plain_redp_frequent', 'train.json'), \"w\") as f:\n",
    "    for txt in tqdm(inter_ds):\n",
    "        doc = {\"text\": txt}\n",
    "        f.write(json.dumps(doc) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a24ed7-fcd1-4c3d-b924-f474158a355e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
