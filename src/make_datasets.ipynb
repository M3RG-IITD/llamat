{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0a060f-89ff-44f0-8438-ecce917067d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file = []\n",
    "with open('/scratch/cse/btech/cs1200448/MatLlama/ft_ds/train_ft.json', 'r') as f:\n",
    "    for line in f:\n",
    "        json_line = json.loads(line)\n",
    "        file.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e985b350-95c4-4dff-b39b-943880f570f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a6045-d378-4e91-893e-fd75639fc2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e00d0-8661-421e-b76b-ecf53ef836f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad = json.load(open('../finetune/dataset/squadv2/squad_dev.json', 'r'))\n",
    "# hellaswag = json.load(open('../finetune/dataset/hellaswag/hellaswag_val.jsonl', 'r'))\n",
    "hellaswag = []\n",
    "with open('../finetune/dataset/hellaswag/hellaswag_val.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        json_line = json.loads(line)\n",
    "        hellaswag.append(json_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8217b7c-53f5-4bf2-bdb4-061663c038fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(hellaswag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15bd1a-d1bb-4e54-991e-1db1bd1befe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hellaswag_dev = hellaswag[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac1a0cd-efe7-46c0-96fd-20deb87fb8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hellaswag_val = []\n",
    "for i in hellaswag_dev:\n",
    "    example = {'task':'completion', 'dataset':'hellaswag', 'input':i['ctx'], 'ind':i['ind'], 'options':i['endings'], 'answer':i['label']}\n",
    "    hellaswag_val.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81bd863-230a-4286-acc0-13dc5c167627",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_val = []\n",
    "shot = 2\n",
    "num_qn_per_ctx = 1\n",
    "for topic in squad['data']:\n",
    "    title = topic['title']\n",
    "    for paragraph in topic['paragraphs']:\n",
    "        ctx = paragraph['context']\n",
    "        qas = [i for i in paragraph['qas'] if len(i['answers']) != 0]\n",
    "        if len(qas) < shot+1:\n",
    "            continue\n",
    "        common_prompt = f'Title: {title}\\n\\nBackground: {ctx}\\n\\n'\n",
    "        for which_shot in range(shot):\n",
    "            common_prompt+= f'Q: {qas[which_shot][\"question\"]}\\n\\nA: {qas[which_shot][\"answers\"][0][\"text\"]}\\n\\n'\n",
    "        for question in qas[shot:num_qn_per_ctx+shot]:\n",
    "            answers = list(set([ans['text'] for ans in question['answers']]))\n",
    "            example = {'task':'qna', 'dataset':'squadv2', 'qid':question['id'], 'valid_answers':answers}\n",
    "            example['input'] = common_prompt + 'Q: ' + question['question'] + '\\n\\nA: '\n",
    "            squad_val.append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fd74a4-d2f4-4666-94d9-cd7d2fdddab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matsci = json.load(open('/home/cse/btech/cs1200448/MatLlama/finetune/custom-finetuning-data/val_ft.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069a7e0-afab-4c87-ae8c-424b39039933",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {}\n",
    "for i in matsci:\n",
    "    if (i['task'], i['dataset']) not in types:\n",
    "        types[(i['task'], i['dataset'])] = [i]\n",
    "    else:\n",
    "        types[(i['task'], i['dataset'])].append(i)\n",
    "matsci_val = {i:[] for i in types.keys()}\n",
    "\n",
    "for type, qns in types.items():\n",
    "    if type == ('pc', 'glass_non_glass'):\n",
    "        shot = 2\n",
    "        common_prompt = \"Is the following sentence related to inorganic glass research?\\n\\n\"\n",
    "        for which_shot in range(shot):\n",
    "            common_prompt+= f'Sentence: {qns[which_shot][\"input\"]}\\n\\nA: {qns[which_shot][\"output\"]}\\n\\n'\n",
    "        for qn in qns[shot:]:\n",
    "            example = {'task':type[0], 'dataset':type[1]}\n",
    "            example['output'] = qn['output']\n",
    "            example['input'] = common_prompt + 'Sentence: ' + qn['input'] + '\\n\\nA: '\n",
    "            matsci_val[type].append(example)\n",
    "            \n",
    "    if type == ('sc', 'sofc_sent'):\n",
    "        shot = 2\n",
    "        common_prompt = \"Is the following sentence related to solid oxide fuel cell research?\\n\\n\"\n",
    "        for which_shot in range(shot):\n",
    "            common_prompt+= f'Sentence: {qns[which_shot][\"input\"]}\\n\\nA: {qns[which_shot][\"output\"]}\\n\\n'\n",
    "        for qn in qns[shot:]:\n",
    "            example = {'task':type[0], 'dataset':type[1]}\n",
    "            example['output'] = qn['output']\n",
    "            example['input'] = common_prompt + 'Sentence: ' + qn['input'] + '\\n\\nA: '\n",
    "            matsci_val[type].append(example)\n",
    "            \n",
    "    if type == ('re', 'sc_comics'):\n",
    "        shot = 2\n",
    "        common_prompt = \"Extract the relation between the entities from the context.\\n\\nOptions : condition, equivalent, target.\\n\\n\"\n",
    "        for which_shot in range(shot):\n",
    "            input = qns[which_shot][\"input\"]\n",
    "            output = qns[which_shot][\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            e1 = input[0].split(\"ENTITY1: \")[1]\n",
    "            e2 = input[1].split(\"ENTITY2: \")[1]\n",
    "            assert len(input) == 3\n",
    "            common_prompt+= f'{input[2]}\\nQ: What is the relation between {e1} and {e2}?\\n\\nA: {output}\\n\\n'\n",
    "        for qn in qns[shot:]:\n",
    "            if _ in shots:\n",
    "                continue\n",
    "            input = qn[\"input\"]\n",
    "            output = qn[\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            e1 = input[0].split(\"ENTITY1: \")[1]\n",
    "            e2 = input[1].split(\"ENTITY2: \")[1]\n",
    "            assert len(input) == 3\n",
    "            example = {'task':type[0], 'dataset':type[1]}\n",
    "            example['output'] = output\n",
    "            example['input'] = common_prompt + f'{input[2]}\\nQ: What is the relation between {e1} and {e2}?\\n\\nA: '\n",
    "            matsci_val[type].append(example)\n",
    "\n",
    "    if type == ('re', 'structured_re'):\n",
    "        common_prompt = \"Extract the relation between the entities from the context.\\n\\nOptions : coulombic efficiency, capacity, conductivity, voltage, energy.\\n\\n\"\n",
    "        shots = [0,2]\n",
    "        for which_shot in shots:\n",
    "            input = qns[which_shot][\"input\"]\n",
    "            output = qns[which_shot][\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            e1 = input[0].split(\"ENTITY1: \")[1]\n",
    "            e2 = input[1].split(\"ENTITY2: \")[1]\n",
    "            assert len(input) == 3\n",
    "            common_prompt+= f'{input[2]}\\nQ: What is the relation between {e1} and {e2}?\\n\\nA: {output}\\n\\n'\n",
    "        for _, qn in enumerate(qns):\n",
    "            if _ in shots:\n",
    "                continue\n",
    "            input = qn[\"input\"]\n",
    "            output = qn[\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            e1 = input[0].split(\"ENTITY1: \")[1]\n",
    "            e2 = input[1].split(\"ENTITY2: \")[1]\n",
    "            assert len(input) == 3\n",
    "            example = {'task':type[0], 'dataset':type[1]}\n",
    "            example['output'] = output\n",
    "            example['input'] = common_prompt + f'{input[2]}\\nQ: What is the relation between {e1} and {e2}?\\n\\nA: '\n",
    "            matsci_val[type].append(example)\n",
    "\n",
    "    if type == ('ee', 'sc_comics'):\n",
    "        common_prompt = \"Extract the roles in doping for the given argument.\\n\\n\"\n",
    "        shots = [1]\n",
    "        for which_shot in shots:\n",
    "            input = qns[which_shot][\"input\"]\n",
    "            output = qns[which_shot][\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            assert len(input) == 4\n",
    "            output = output.split('\\n')\n",
    "            output = [i.split(' : ') for i in output]\n",
    "            for otp in output:\n",
    "                common_prompt+= f'{input[3]}\\nQ: Is {otp[0]} the site or the dopant?\\n\\nA: {otp[1]}\\n\\n'\n",
    "        for _, qn in enumerate(qns):\n",
    "            if _ in shots:\n",
    "                continue\n",
    "            input = qn[\"input\"]\n",
    "            output = qn[\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            assert len(input) == 4\n",
    "            output = output.split('\\n')\n",
    "            output = [i.split(' : ') for i in output]\n",
    "            # print(_,input,output)\n",
    "            for otp in output:\n",
    "                example = {'task':type[0], 'dataset':type[1]}\n",
    "                example['output'] = otp[1]\n",
    "                example['input'] = common_prompt + f'{input[3]}\\nQ: Is {otp[0]} the site or the dopant?\\n\\nA: '\n",
    "                matsci_val[type].append(example)\n",
    "\n",
    "    if type == ('sar', 'synthesis_actions'):\n",
    "        common_prompt = \"Extract the synthesis action for the Verb in the given sentence.\\n\\nOptions : cooling, heating, mixing, non-altering, purification, reaction, shaping, starting.\\n\\n\"\n",
    "        shots = [1]\n",
    "        for which_shot in shots:\n",
    "            input = qns[which_shot][\"input\"]\n",
    "            output = qns[which_shot][\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            output = output.split('\\n')\n",
    "            output = [i.split(' : ') for i in output]\n",
    "            input = \"\\n\".join([i for _,i in enumerate(input) if _ != 0])\n",
    "            for otp in output:\n",
    "                common_prompt+= f'{input}\\nQ: What is the synthesis action for {otp[0]}?\\n\\nA: {otp[1]}\\n\\n'\n",
    "        for _, qn in enumerate(qns):\n",
    "            if _ in shots:\n",
    "                continue\n",
    "            input = qn[\"input\"]\n",
    "            output = qn[\"output\"]\n",
    "            input = input.split('\\n')\n",
    "            input = \"\\n\".join([i for _,i in enumerate(input) if _ != 0])\n",
    "            output = output.split('\\n')\n",
    "            output = [i.split(' : ') for i in output]\n",
    "            # print(_,input,output)\n",
    "            for otp in output:\n",
    "                example = {'task':type[0], 'dataset':type[1]}\n",
    "                example['output'] = otp[1]\n",
    "                example['input'] = common_prompt + f'{input}\\nQ: What is the synthesis action for {otp[0]}?\\n\\nA: '\n",
    "                matsci_val[type].append(example)\n",
    "\n",
    "    if type == ('ner', 'sc_comics'):\n",
    "        num_examples = 500\n",
    "        which_entities = ['material', 'process', 'element', 'property']\n",
    "        shots = [0,5]\n",
    "        # material, doping, sc, value, process, characterization, element, property, main\n",
    "        for entity in which_entities:\n",
    "            common_prompt = f\"Extract the {entity} in the following sentences. If there are none, respond with 'None'. If there are multiple, separate them with ';'.\\n\\n\"\n",
    "            for which_shot in shots:\n",
    "                input = qns[which_shot][\"input\"]\n",
    "                output = qns[which_shot][\"output\"]\n",
    "                input = input.split('\\n')[-1]\n",
    "                output = output.split('\\n')\n",
    "                output = [i.split(' : ') for i in output]\n",
    "                output = [i for i in output if i[1] == entity]\n",
    "                output = \";\".join(list(set([i[0] for i in output])))\n",
    "                common_prompt+= f'{input}\\nQ: What are the {entity}?\\n\\nA: {\"None\" if len(output) == 0 else output}\\n\\n'\n",
    "            for _, qn in enumerate(qns[:num_examples]):\n",
    "                if _ in shots:\n",
    "                    continue\n",
    "                input = qn[\"input\"]\n",
    "                output = qn[\"output\"]\n",
    "                input = input.split('\\n')[-1]\n",
    "                output = output.split('\\n')\n",
    "                output = [i.split(' : ') for i in output]\n",
    "                output = [i for i in output if i[1] == entity]\n",
    "                if len(output) == 0:\n",
    "                    output = \"None\"    \n",
    "                else:\n",
    "                    output = \";\".join(list(set([i[0] for i in output])))\n",
    "                example = {'task':type[0], 'dataset':type[1]}\n",
    "                example['output'] = output\n",
    "                example['input'] = common_prompt + f'{input}\\nQ: What are the {entity}?\\n\\nA: '\n",
    "                matsci_val[type].append(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81c6477-8023-430c-91bf-8aa65ce47d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(*[[j,len(i)] for j,i in matsci_val.items()])\n",
    "print(len(hellaswag_val))\n",
    "print(len(squad_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8df765-68f0-4a84-8567-b68138aed72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zshot_val = squad_val\n",
    "# zshot_val = hellaswag_val + squad_val\n",
    "for i,j in matsci_val.items():\n",
    "    zshot_val += j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ef499a-b3d8-4ec9-bb1b-dc58370255dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# json.dump(zshot_val, open('../finetune/custom-finetuning-data/Kshot-val.json', 'w'), indent = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b566658c-2696-4b8b-bb2a-1ba60d4ee133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "kshot = json.load(open('../finetune/custom-finetuning-data/Kshot-val.json', 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721ed611-9c93-41b7-8ca4-e3e9045ff048",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i for i in kshot if i['task'] == 'sc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38331567-9910-4a98-bbb8-82fccc075c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sum([1 for i in a if i['output'] == 'yes'])\n",
    "c = sum([1 for i in a if i['output'] == 'no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339b3ac7-8b2d-48c6-87e2-64f9bbaaf2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2b979b-011e-409e-b3e9-5074bc144392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in matsci:\n",
    "#     if item['task']=='ner' and item['dataset']=='matscholar':\n",
    "#         tasks = item['input'].split('SENTENCE:')[0].split('WORDS:')[1].split(',')\n",
    "#         sentence = item['input'].split('SENTENCE:')[1]\n",
    "#         outputs = item['output']\n",
    "#         options = ['b-mat', 'i-mat', 'b-spl', 'i-spl', 'b-dsc', 'i-dsc', 'b-pro', 'i-pro', 'b-apl', 'i-apl', 'b-smt', 'i-smt', 'b-cmt', 'i-cmt']\n",
    "#         sample = 'Context: '\n",
    "#         sample += sentence + '\\n\\n'\n",
    "#         sample += 'Options: '\n",
    "#         sample += ', '.join(options) + '\\n\\n'\n",
    "#         tasks = list(map(lambda x: x.replace('\\n', '').strip(), tasks))\n",
    "#         if len(tasks)<=2:\n",
    "#             continue\n",
    "#         outputs = outputs.split('\\n')\n",
    "#         output_dict = dict()\n",
    "#         for output in outputs:\n",
    "#             output_dict[output.split(':')[0].strip()] = output.split(':')[1].strip()\n",
    "\n",
    "#         try:\n",
    "#             sample += f'Q: Named entity for {tasks[0]}\\n\\nA: {output_dict[tasks[0]]}\\n\\n'\n",
    "#             sample += f'Q: Named entity for {tasks[1]}\\n\\nA: {output_dict[tasks[1]]}\\n\\n'\n",
    "        \n",
    "#             for task in tasks[2:]:  \n",
    "#                 try:\n",
    "#                     dataset.append({\n",
    "#                         'input':sample + f'Q: Named entity for {task}\\n\\nA: \\n\\n',\n",
    "#                         'output': output_dict[task],\n",
    "#                         'task': 'ner',\n",
    "#                         'dataset': 'matscholar'\n",
    "#                    })\n",
    "#                 except:\n",
    "#                     continue\n",
    "#         except:\n",
    "#             continue\n",
    "#     if item['task']=='ner' and item['dataset']=='sofc_token':\n",
    "#         tasks = item['input'].split('SENTENCE:')[0].split('WORDS:')[1].split(',')\n",
    "#         sentence = item['input'].split('SENTENCE:')[1]\n",
    "#         outputs = item['output']\n",
    "#         options = ['b-mat', 'i-mat', 'b-spl', 'i-spl', 'b-dsc', 'i-dsc', 'b-pro', 'i-pro', 'b-apl', 'i-apl', 'b-smt', 'i-smt', 'b-cmt', 'i-cmt']\n",
    "#         sample = 'Context: '\n",
    "#         sample += sentence + '\\n\\n'\n",
    "#         sample += 'Options: '\n",
    "#         sample += ', '.join(options) + '\\n\\n'\n",
    "#         tasks = list(map(lambda x: x.replace('\\n', '').strip(), tasks))\n",
    "#         if len(tasks)<=2:\n",
    "#             continue\n",
    "#         outputs = outputs.split('\\n')\n",
    "#         output_dict = dict()\n",
    "#         for output in outputs:\n",
    "#             output_dict[output.split(':')[0].strip()] = output.split(':')[1].strip()\n",
    "\n",
    "#         try:\n",
    "#             sample += f'Q: Named entity for {tasks[0]}\\n\\nA: {output_dict[tasks[0]]}\\n\\n'\n",
    "#             sample += f'Q: Named entity for {tasks[1]}\\n\\nA: {output_dict[tasks[1]]}\\n\\n'\n",
    "        \n",
    "#             for task in tasks[2:]:  \n",
    "#                 try:\n",
    "#                     dataset.append({\n",
    "#                         'input':sample + f'Q: Named entity for {task}\\n\\nA: \\n\\n',\n",
    "#                         'output': output_dict[task],\n",
    "#                         'task': 'ner',\n",
    "#                         'dataset': 'sofc_token'\n",
    "#                    })\n",
    "#                 except:\n",
    "#                     continue\n",
    "#         except:\n",
    "#             continue\n",
    "\n",
    "#     if item['task']=='pc':\n",
    "#         sample = 'Context: '\n",
    "#         sample += item['input'] + '\\n\\n'\n",
    "#         sample += 'Q: Is the above paragraph related to inorganic glass research?\\n\\nA: '\n",
    "#         dataset.append({\n",
    "#             'input': sample,\n",
    "#             'output': item['output'],\n",
    "#             'task': 'pc',\n",
    "#             'dataset': 'glass_non_glass'\n",
    "#         })\n",
    "#     if item['task']=='sc':\n",
    "#         sample = 'Context: '\n",
    "#         sample += item['input'] + '\\n\\n'\n",
    "#         sample += 'Q: Is this paragraph related to solid oxide fuel cell (SOFC) research?\\n\\nA: '\n",
    "#         dataset.append({\n",
    "#             'input': sample,\n",
    "#             'output': item['output'],\n",
    "#             'task': 'sc',\n",
    "#             'dataset': 'sofc_sent'\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448f029-de2b-4af1-9c74-febb79acd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "with open('/home/cse/btech/cs1200448/MatLlama/finetune/dataset/squadv2/squad_train.json', 'r') as f:\n",
    "\tdata = json.load(f)\n",
    "\n",
    "ds = []\n",
    "for item in data['data']:\n",
    "\tfor para in item['paragraphs']:\n",
    "\t\tcontext = para['context']\n",
    "\t\ttry:\n",
    "\t\t\tqas = list(map(lambda x: (x['question'], x['answers'][0]['text']), para['qas']))\n",
    "\t\t\tds.append([context, qas])\n",
    "\t\texcept:\n",
    "\t\t\tcontinue\n",
    "\n",
    "SYSTEM = \"You will be given a text and you have to answer the question that follows it using information from the text.\"\n",
    "\n",
    "train_ds = []\n",
    "val_ds = []\n",
    "for context, qas in ds:\t\n",
    "\tfor q, a in qas:\n",
    "\t\ttemp = random.random()\n",
    "\t\tif temp < 0.023:\n",
    "\t\t\ttrain_ds.append({'system': SYSTEM,\n",
    "\t\t\t\t\t 'question': context+' '+q,\n",
    "\t\t\t\t\t 'answer': a})\n",
    "\t\telif 0.023 < temp < 0.046:\n",
    "\t\t\tval_ds.append({'system': SYSTEM,\n",
    "\t\t\t\t       'question': context+' '+q,\n",
    "\t\t\t\t       'answer': a})\n",
    "\n",
    "with open('/scratch/cse/btech/cs1200448/MatLlama/ft_ds/train_ft.jsonl', 'a') as f:\n",
    "\tfor doc in train_ds:\n",
    "\t\tf.write(json.dumps(doc)+'\\n')\n",
    "\n",
    "with open('/scratch/cse/btech/cs1200448/MatLlama/ft_ds/val_ft.jsonl', 'a') as f:\n",
    "    for doc in val_ds:\n",
    "            f.write(json.dumps(doc)+'\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matllama2.0",
   "language": "python",
   "name": "matllama2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
