Traceback (most recent call last):
  File "/home/cse/btech/cs1200389/MatLlama/MatLLaMA/src/inference_newtasks/final_upload/ft_eval.py", line 7, in <module>
    import vllm
ModuleNotFoundError: No module named 'vllm'
Traceback (most recent call last):
  File "/home/cse/btech/cs1200389/MatLlama/MatLLaMA/src/inference_newtasks/final_upload/ft_eval.py", line 7, in <module>
    import vllm
  File "/home/cse/btech/cs1210556/.conda/envs/infer_env_llama3/lib/python3.10/site-packages/vllm/__init__.py", line 3, in <module>
    from vllm.engine.arg_utils import AsyncEngineArgs, EngineArgs
  File "/home/cse/btech/cs1210556/.conda/envs/infer_env_llama3/lib/python3.10/site-packages/vllm/engine/arg_utils.py", line 8, in <module>
    import torch
  File "/home/cse/btech/cs1210556/.conda/envs/infer_env_llama3/lib/python3.10/site-packages/torch/__init__.py", line 290, in <module>
    from torch._C import *  # noqa: F403
KeyboardInterrupt
